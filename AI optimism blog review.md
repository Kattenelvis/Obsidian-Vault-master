

Hello! I was in a conversation about AI risk and learnt that you're an AI researcher, not just someone who wrote a couple blog posts on AI. Congratulations on such a position! 

[AI is easy to control – AI Optimism (optimists.ai)](https://optimists.ai/2023/11/28/ai-is-easy-to-control/)
You say there's a 1% probability of X-risk from AI, what would you say to someone who believes that X-risk has <0.001% or about the order of magnitude of an alien invasion?

Neural networks are not white boxes just because you know the backpropagation algorithm. The problem is eliciting information from the neural-network, of which the information states are hidden to us, as they're mostly a jumbled mess. Now you're an interpretability researcher, so I'm going to assume you already know this, and just have a different definition of black/white box. Alternatively, you'd consider the brain is *comparatively more like* a black box than a deep neural network?

Secret murder plots may still be what's most effective in the long run, especially if it ends up being the best approach forward. Though that may more be the case of LLMs than basic ANNs 

Values are easy to learn, are you worried about value-lock in?

"1. Values are pervasive in language model pre-training datasets. Essentially every domain of discourse contains implicit or explicit evaluative judgements. In contrast, the types of knowledge needed for dangerous capabilities appear at much lower frequencies in the training corpus."

Do you think the AI could learn moral anti-realism, value anti-realism, moral skepticism etc. from this training data in a way which could disrupt this training? 

"1.   
    Since values are _shared_ and understood by almost everyone in a society, they cannot be very complex. Unlike science and technology, where division of labor enables the accumulation of ever more complex knowledge, values must remain simple enough to be learned by children within a few years."
    
Is that really true? Are they so ubiquitous? Why do we have specialists in bioethics etc. then?




[Counting arguments provide no evidence for AI doom – AI Optimism (optimists.ai)](https://optimists.ai/2024/02/27/counting-arguments-provide-no-evidence-for-ai-doom/)






