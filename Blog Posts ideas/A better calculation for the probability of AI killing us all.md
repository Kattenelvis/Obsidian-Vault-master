

AGI is not possible arguments and counter-arguments:

lucas-penrose. 

Chinese Room: Limited to some models of the time, symbol grounding problem is solvable

Dreyfus: Limited to some models of the time, frame problem is solvable (possibly even without embodiment)

No-Free-Lunch-Theorem: Only applicable to subsets of turing machines

Mathematical modelling: Learning models could in principle predict what humans can

Rice's theorem: AI models can generate code, test and iterate. It doesn't have to generate the code at once and know from syntax alone what it does. But it might, just like humans, be good at predicting what code does.



Argument Stuart Russell
![[Pasted image 20250423210804.png]]

The singularity argument (Chalmers)

A --> A+ -->A++ ....



Bostr√∂m-Omohundro theory of rationality. 

1. Orthogonality Thesis: Strong version: Any goal is compatible with any level of intelligence. Probably false, a weaker version excludes trivialities 

2. Convergent instrumentality: A small set of subgoals will be useful for a very large set of end goals.





In short:

AGI is possible (feasible, likely)
If AGI is possible (feasible, likely), then ASI is possible (feasible, likely)
if ASI is possible (feasible, likely), then human extinction risk from ASI is possible (feasible, likely)


