vs FDT?

decision theories

FDT implies murdering people??? Something to do with Roko's Basilisk



Boström meta-newcomb

The decision theory paper in my course on how for every thought experiment for EDT one can build for CDT and vice versa




Brief introduction to intuitions, method of cases etc?

CDT --> Ought(Two-Boxing)
Not Ought(Two-Box)
Not CDT

CDT --> Ought(Two-Boxing)
CDT
Ought(Two-Boxing)



The act itself gives you evidence that agents, atleast one's similar to you in some relevant way, will also act in that way, and you are rationally incentivized to act based on what evidence your act gives you.




Acausal trade, Hyperrationality

Yudkowski, TDT and FDT?

CDT is more intuitive


CDT
$EU_{CDT}(A) = \Sigma_{i=0}^n P(O_i) U(O_i)$
$EU_{EDT}(A) = \Sigma_{i=0}^n P(O_i|A) U(O_i)$



Take on a radically Humean approach: there is no causation, I'm trying to predict my field of sensations, so of course my actions is evidence for future sensation states


Or Determinism


QBism

Calvinism, or, in a deterministic universe, what you do gives you evidence. 


Pascal's wager and Roko's Basilisk



If we have $n$ choices with 2 options each, then there are $2^n$ decision theories?

And with say $n_2$ choices with 2 options, $n_3$ choices with 3 options etc we get a total of 

$2^n_2 3^n_3...k^n_k$

$\Pi_2^k i^n_i$




Alternatively, argument for EDT:

Humean causality
If humean causality than only EDT is true
EDT is true





An example: International politics. Imagine USA and China on an agreement. Realist interpretation. One uses CDT and the other EDT. The one using EDT and the other predicts? International politics newcomb. 



Newcomb prisoners dilemma



> Imagine an agent that is going to face first Newcomb’s problem, and then the smoking lesion problem. Imagine measuring them in terms of utility achieved, by which we mean measuring them by how much utility we expect them to attain, on average, if they face the dilemma repeatedly. The sort of agent that we’d expect to do best, measured in terms of utility achieved, is the sort who one-boxes in Newcomb’s problem, and smokes in the smoking lesion problem. But Gibbard and Harper (1978) have argued that rational agents can’t consistently both one-box and smoke: they must either two-box and smoke, or one-box and refrain—options corresponding to CDT and EDT, respectively. 



Uniqueness of philsoophical thought: Having thought P, one has evidence that some think P, hence decreasing the subjective probability that P is a unique thought. 



The twin prisoners dilemma
The newcomb predictor has a mini-twin in his head that one is acting against.
By FDT, one ought to cooperate when playing against a twin. 





Everyday example?

I can choose or not choose to be nice at some small cost to myself.

Does EDT advice me to be nice since it gives me evidence that other nice people will be nice to me? CDT will say that my choice will not affect how nice others are, so I should not be nice (in this one-shot case with no other negative effects)

Purchase food to a poor person or not
Outcome 99% it's just a poor person, 1% it's a social experiment and you win $10000

$EU_{CDT}(a) = U(o) P(a \square\to o)$
$EU_{EDT}(a) = U(o) P(o|a)$


$EU_{CDT}(b) = -9.90  + 100$
Same for EDT tbh

Hmmm.......

Buying food for poor people gives evidence others act like you do, dropping the probability?
Actually let's calculate EDT

EDT involves Bayesian updating

$P(o_1|a) = P(a|o_1)P(o_1)/P(a)$



$EU_{EDT}(a) = 0.99 P(o_1|a) + 0.01P(o_2|a)$
$= 0.99 P(o_1|a) + 0.01P(o_2|a)$




