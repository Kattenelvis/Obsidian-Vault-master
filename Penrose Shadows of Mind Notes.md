
"But there appears to be another logical consequence of these potential developments that may well strike us as genuinely alarming. Would not these computers eventually make human beings themselves superfluous? If the computer-guided robots turn out to be our superiors in every respect, then will they not find that they can run the world better without the need of us at all? Humanity itself will then have become obsolete. Perhaps, if we are lucky, they might keep us as pets, as Edward Fredkin once said; or if we are clever, we might be able to transfer the 'patterns of information' that are 'ourselves' into robot form, as Hans Moravec (1988) has insisted; or perhaps we will not be that lucky and will just not be that clever . . ."


"It seems to me that there are at least four different viewpoints-or extremes of viewpoint-that one may reasonably hold on the matter: 

A. All thinking is computation; in particular, feelings of conscious awareness are evoked merely by the carrying out of appropriate computations.

B. Awareness is a feature of the brain's physical action; and whereas any physical action can be simulated computationally, computational simulation cannot by itself evoke awareness. 

C. Appropriate physical action of the brain evokes awareness, but this physical action cannot even be properly simulated computationally. 

D. Awareness cannot be explained by physical, computational, or any other scientific terms."

"My own position is that questions of mind, though they lie very uncomfortably with present-day scientific understanding, should not be regarded as being forever outside the realms of science. If science is yet incapable of saying much that is of significance concerning matters of the mind, then eventually science must enlarge its scope so as to accommodate such matters, and perhaps even modify its very procedures."

"Let us consider what seems to be the other extreme: the viewpoint d. Those who adhere to the standpoint that is often referred to as strong AI (strong Artificial Intelligence) or sometimes hard AI, or fu nctionalism,4 would come under this heading-although some people might use the term 'functionalism' in a way that could include certain versions of"

"There are undoubtedly many different versions of viewpoint d. (See Sloman (1992) for a long list of alternative computational viewpoints.)"

"Some would not even allow that there is such a phenomenon as 'conscious awareness' at all, whereas others would accept the existence of this phenomenon, but regard it as just some kind of 'emergent property' (cf. also §4.3 and §4.4) that comes along whenever a sufficient degree of complication (or sophistication, or self reference, or whatever)"


"The acceptance of this kind of argument, which basically is what is referred to as a Turing test,6 is in essence what distinguishes d from !14. According to d, any computer-controlled robot which, after sustained questioning, convincingly behaves as though it possesses consciousness, must be considered actually to be conscious-whereas according to !14, a robot could perfectly well behave exactly as a conscious person might behave without itself actually possessing any of this mental quality."

"What about f!J then? I think that it is perhaps the viewpoint that many would regard as 'scientific common sense'. lt is sometimes referred to as weak (or soft ) AI."

A is strong AI
B is weak AI

"The viewpoints .91, !JI, rc, �. as defined above, are intended to represent extremes, or polarities, of possible stances that one might choose to take. I can accept that some people may feel that their own viewpoints do not fit clearly into any of these categories, but perhaps lie somewhere between them, or cut across some of them. There are certainly many possible gradations of belief between .91 and !JI, for example (see Sloman 1992). There is even a view, not uncommonly expressed, that might best be regarded as a combination of .91 and £d (or perhaps fJI and £d)-a possibility that will actually feature significantly in our later deliberations. According to this view, the brain's action is indeed that of a computer, but it is a computer of such wonderful complexity that its imitation is beyond the wit of man and science, being necessarily a divine creation of God-the 'best programmer in the business'!9"




"There are, however, other approaches to the computational issues raised by continuous systems, in which the systems are treated as mathematical structures in their own right, with their own notion of 'computability'-a notion which generalizes the idea of Turing computability from the discrete to the continuous. 1 2 Using such a notion, it becomes unnecessary to approxi mate a continuous system by discrete parameters in order that the conventional notion of Turing computability can be applied. Such ideas are interesting from the mathematical point of view, but unfortunately they do not seem to have achieved, as yet, the compelling naturalness and uniqueness that applies to the standard notion of Turing computability for discrete systems. Moreover, there are certain anomalies whereby a technical 'non-computabil ity' arises for simple systems where it is not clear that such a terminology is really appropriate (e.g. even for the simple 'wave equation' of physics; cf. Pour el and Richards (1981 ), ENM pp. 187-8). It should be mentioned, on the other hand, that some fairly recent work (Rubel 1989) has shown that theoretical analogue computers, belonging to a certain rather broad class, cannot reach beyond ordinary Turing computability. I believe that these are interesting and important matters which will be illuminated by further research. However it is not clear to me that this body of work, as a whole, has yet reached the point where it can be applied in a definitive way to the issues under discussion here."




https://www.youtube.com/watch?v=_rI2kVWjPJs&t=1593s

Lecture at one point. Finite and discrete NON-COMPUTATIONAL rules. 

Will tiling x tile the plane? If yes, move one step, if no, move two steps. It is undecidable whether the shapes tile the plane. Ergo it's uncomputable. 




Idea: So it appears that the premises in Penrose's and Lucas's are.
1. Gödel's incompleteness theorem (and hence the 3 premises therein, that one has a 1. finitely axiomatizable 2. consistent formal system with atleast 3. peano arithmetic)
2. Platonism about mathematics and/or finishing infinite mathematical reasoning steps in finite time
3. Human minds are consistent/would implement a consistent computation if computational?

Conclusion: Human minds are not computational.




https://www.cantorsparadise.org/platonist-roger-penrose-sees-mathematical-truths-61a45840fe00/

> So [Alan Turing](https://en.wikipedia.org/wiki/Alan_Turing?ref=cantorsparadise.org) is a good counterweight to bring in here.

> Although Turing accepted Gödel’s theorems, he didn’t also accept some of the things which were said to be consequences of his theorems. (Many see Turing’s [Halting problem](https://en.wikipedia.org/wiki/Halting_problem?ref=cantorsparadise.org) as the “computational equivalent” of Gödel’s first incompleteness theorem.) More specifically, Turing accepted that (what Gödel called) “intuition” is used in order to see the truth of a formally unprovable Gödel sentence. What he _didn’t_ accept was that the brain and mind go beyond the “mechanical”. That is, Turing might well have asked Gödel how it is possible that _non-mechanical intuition_ is carried out by a physically and embodied brain. (See Turing’s own [‘Computing Machinery and Intelligence’](https://academic.oup.com/mind/article/LIX/236/433/986238?ref=cantorsparadise.org) — 1950 — for a very clear account of Gödel’s theorems and why he believed that they’d been somewhat overstretched.)

> One other argument Turing offered is this. Because the brain is so complex, it simply _appears_ to to us to transcend its mechanical (or rule-following) nature. He also argued that (what he called) “initiative” doesn’t require uncomputable steps. (See Andrew Hodges’ [‘The Logical and the Physical’](https://books.google.co.uk/books?id=pzf7_sT58PUC&pg=PA667&lpg=PA667&dq=Hodges%2C+%27The+Logical+and+the+Physical%27&ots=KW_o2trFJu&sig=ACfU3U3sm2AtDDrMj94wFHh7yzGSWypaGQ&hl=en&sa=X&ved=2ahUKEwiOr5_Fm67pAhUxonEKHUkbBeYQ6AEwBHoECAoQAQ&ref=cantorsparadise.org#v=onepage&q=Hodges%2C%20%27The%20Logical%20and%20the%20Physical%27&f=false).) However, a machine’s (or computer’s) computations could still go beyond any programmer’s programme. (See also Turing’s [“randomizer”](https://books.google.co.uk/books?id=pzf7_sT58PUC&pg=PA667&lpg=PA667&dq=Hodges%2C+%27The+Logical+and+the+Physical%27&ots=KW_o2trFJu&sig=ACfU3U3sm2AtDDrMj94wFHh7yzGSWypaGQ&hl=en&sa=X&ved=2ahUKEwiOr5_Fm67pAhUxonEKHUkbBeYQ6AEwBHoECAoQAQ&ref=cantorsparadise.org#v=onepage&q=Hodges%2C%20%27The%20Logical%20and%20the%20Physical%27&f=false).)

> All this meant that Turing didn’t conclude (i.e., from Gödel’s theorems) what Penrose later came to conclude about the human mind or consciousness. And it also meant that Turing was happy with the idea of what came to be called (firstly in 1956) [“artificial intelligence”](https://en.wikipedia.org/wiki/Artificial_intelligence?ref=cantorsparadise.org#History).



 