

### Making some sci-fi ideas into reality: Mind Upload, Dyson spheres, ASI




Whenever I am reading or listening to various political debates regarding socialism vs capitalism opr similar ventures, I realize how small the differences in harm reduction really are. The harm reduction that can be made in future-potential governance systems are multiple orders of magnitude more than in any of our wordly government types. Establishing democratic socialism, or well-regulated social-democratic capitalism, or some other system people have planned out, will not manage to decrease more than some human suffering at best. It does not decrease or abolish wild-animal suffering, nor does it take into account the vast amount of untapped resources for enriching or creating more happiness-having consciousnesses, currently tied up as resources in planets and energy in stars. It is like listening to debates about whether or not feudalism, theocracy, merchant republic or nomadic systems are the best. While it is not unecessary to debate or discuss, one must have some degree of future vision, especially with the exponentially increasing speed of technological development. 




### Dangers ahead



### AI governance and regulation


You should be getting into this
33% risk aversion, 33% expected utility, 33% risk seeking. Since the first two imply you should get into AI safety, then there's a >50% probability and therefore taaakee itt wait a asecond this is circular because the risk seeking behaviour has the lowest probability but if you accept it then you'd pick that uhhh. 



### Global agreements, China is not an enemy who never regulates 



### Why you ought to get into AI alignment, AI governance or a high paying career and giving large amounts of money to AI alignment and AI governance organizations


Given our earlier calculations on the probability distributions of various ethical systems, here is why you ought to do it.

Negative utilitarianism: AI alignment is a major form of harm reduction, likewise (or even more) with AI governance. AI governance focuses almost exclusively on different kinds of harm reduction, such as limiting missuse of AI and establishing rules and guidlines for limiting AI uses. 




I think that an ideal future and non-earthly post-singularity ideology would have the following doctrines:

1. Super Intelligence
2. Post Human Transcendence
3. Consciousness Crafting
4. Radical Industrialism
5. Dynamic Value System


### Super Intelligence

Definition of intelligence in this context: The ability for an agent to achieve their goals.

This rather informal definition gives us a decent start. The idea of a superintelligence first came about when ideas of the technological singularity was around. The idea is that a self-improving artificial general intelligence (AGI) would eventually improve itself up to the point of an artificial super intelligence (ASI). Even if there may be other ways of achieving super intelligence, which is why this part of the article generalizes away from a particular instantiation of a super intelligence, it is the most likely approach. Genetic engineering may be too slow in comparison. 

So if we have a superintellingece, then what will it do? Well that depends. 

If Orthogonality thesis is true:
We should submit to its higher values. Humanities values would then clearly be, below the true values. 

Atleast if moral realism is true, and motivational internalism is true. 

They're not omniscient, but they might aswell be

They are optimal optimizers
### Post Human Trasncendence

So let's say we have invented a superintelligence. What happends to us humans them? We will transcend with it. 


### Consciousness crafting
With Dyson spheres or similar structures, one has the energy to craft any kind of conscious experience that we desire. This is true even if consciousness is not computational. If consciousness is non-computational, and is for some reason only supervenient/identical/emergent on biological physical objects, then we can still build large structures, perhaps with brain in vats, or neurons placed in some sort of configuration, to generate the experiences we want. 

This might be false if phenomenal experience is not supervenient, identical or emergent from physical objects or properties. So we should figure out whether or not this is true first before we start consciousness crafting.

With the help of consciousness crafting, we can create intense and amazing aesthetic experiences. If you're like me, or like most humans, and value art, then a post-human transcendence and superintelligence will allow for the creation of new kinds of art that has never before seen. Every single modality of experience can be a part of an aesthetic experience, from audio and sight to smell and proprioception. Such complete experiences can allow us to experience pretty much whatever we want. If you, like most humans, value agency or freedom to some extent, then all of these experiences can be interactive virtual worlds. Virtual worlds are not "fake", but just as real as reality itself [chalmers, 201x]. 

Nozick's experience machine is a thought experiment about how ethical it is to enter such a machine. What I advocate for is that yes, it is ethical, and we should build one in real life. 

How to prevent Fahrenheit 451: idk lol


### Radical Industrialism

Industrialism, as an ethical negation of and political opponent force to ecologism, posits that atleast some amount of destruction of the natural environment is preferable to protection. I will tend to agree with this, with some caveats that we should protect the environment to minimize existential risk (specifically from global warming and resource wars) aswell as to protect the beauty of nature (specifically for my daily walks between 12:30-14:30). The main reason some amount of environmental destruction is acceptable is because it minimizes suffering through the production of happiness increasing products (so long as the workplaces themselves don't lead to increased suffering, for instance in sweatshops or slave labor). 

However, under the assumption that the technological singularity has occurred, with consciousness crafting and post human transcendence, then it follows that there is no instrumental reason to retain any nature at all. Risk from extinction is no longer a problem, nature at this point is completely controllable by the post-humans. Natural beauty is also no longer a problem, as any simulation will be able to either replicate nature, or produce even more beautiful experiences. However what does remain is that production is happiness increasing. So it follows that the reason to destroy the environment is retained, while the reasons against it don't. This allows me to advocate for a kind of radical industrialism, where stars are power plants and planets are resource extraction points. I do not advocate retaining any life, any uplifting of species, or anything of that sort. Planets that are of particular scientific use may be retained, and I'm reluctantly willing to compromise on keeping earth around aswel (as a kind of museum for post-humans to visit - though a simulated earth has a lower risk of being destroyed and can be copied around the universe). As such, I would advocate for the repurpose of nature, given that we have transcended the need for nature. 


