Any philosophical system has to begin with confronting radical skepticism and defeat it. Any philosophical system which can't defeat radical skepticism or deal with skepticism in some way opens itself up to being subject to potentially hard hitting attacks by a radical sceptic. Before we begin formalising a logical description of the world and develop the language of phenomenal experience, as will be done in later chapters, we first need to deal with and settle radical skepticism. This is the case for every philosophical system no matter whether or not its proponent is a more of a sceptic or more of an anti-sceptic. The anti-sceptic just believes to have stronger counter-arguments to skeptical arguments while the sceptic generally agrees with skeptical arguments. 

First we will go over the argument from error, which states that one could always be wrong about anything since one has been wrong in the past. We will accept this line of reasoning, and establish universal revisability, which means that any statement can be revised, even the statement about universal revisability.

Then, we find a counterargument against cartesian scepticism by accepting the existence of phenomenal experience. By accepting phenomena, we mean accepting that there exists something, not necessarily an personal identity or "I" concept, but some phenomenal experience exists with complete certainty. 

Then, we will go ahead and find a counterargument against Pyrrhonian scepticism, also known as Agrippa's trilemma, by constructing a system of "foundherentism". That is to say, we formalise justification chains that are circular as the initial conditions for a belief system, while overtime working towards finding an axiomatic system that can describe one's belief system in its entirety, hopefully in the end finding the complete theory of the world which we will call $T_\omega$. You could say that the axioms are justified in a web of belief. 

We then develop the theory $T_0$ which includes the modal-logical formalisation of the axioms of experience and universal revisability, while 

However, while foundherentism, experience and universal revisability provide powerful responses to Agrippa's trilemma, cartesian scepticism and the argument from error respectively, we find that arguments against solipsism or external world scepticism are not currently sufficient. Some probabilistic estimates can be made, however a separate theory $T^*$ will be constructed which contains some dogmatic axioms which accepts other consciousnesses and the external world. 

We will lastly go over some other attempts at resolving scepticism, such as "intuition" and Moorean solutions. We will attempt to dissect these diagnoses to scepticism and point out their flaws. 

## Argument from error

The argument from error is the claim that we've believed in $p$ at some point before, but we believe $\neg p$ now. Therefore we will be wrong in the future. It's an inductive argument based on earlier mistakes. However, by claiming that one used to believe $p$ as true and later $\neg p$ does not imply that $\neg p$ is true. It could be that one was right from the start. Sometimes one's belief can change back to $p$. So instead it has to be reformulated so as to not assume one has always been wrong: 

(1) There have been many times I have believed some proposition $p$ to be true, only for me to later believe $\neg p$.
(2) Therefore in the future there will exist some belief that $p$ is true, only to later believe $\neg p$.

Formalised in logic (Footnote perhaps?)
For any proposition $p\in\Delta$ where $\Delta$ is a set of beliefs, then $\forall p\in\Delta. B(p)\rightarrow \diamondsuit FB(\neg p)$ where $B$ is modal operator for 'belief' and $F$ is modal operator for 'in the future' and $\diamondsuit$ possible. In English, "there exists a possible future where you believe the opposite to what you believe now for all propositions." [Citation SEP temporal logic and doxastic logic]

To even be able to formalise that argument, one needs to have quite a loaded amount of notions such as temporal and alethic modalities. 

Another potential way of formalising it is via inductive logic instead, which could look as the following

Inductive logic formalization
Let $\delta\in\Delta$ be a set which only contains beliefs that have been changed atleast once. Then $\frac{|\delta|}{|\Delta|}$ is the frequency of changed beliefs. Therefore, an arbitrary belief has probability $\frac{|\delta|}{|\Delta|}$ of being changed at some point in the future. [Citation of SEP page on inductive logic]

This formalisation only requires sets, and some basic notions of probability to be formalised. 

The inductive argument justifies the following meta-sceptical inductive argument:

(1) There have been many times I have believed some proposition that is a premiss for a sceptical argument $p_s$ to be true, only for me to later believe $\neg p_s$.

(2) Therefore in the future there will exist some belief that is a premiss for a sceptical argument such that I believe $p_s$ is true, only to later believe $\neg p_s$.

The mere possibility of being wrong on any premiss in any of a large range of sceptical argument is enough to suspend beliefs about every belief, including ones about sceptical arguments. To achieve this, some kind of logic of revisability needs to be formalised, as a way to describe how beliefs can be revised and changed over time, as well as their degree of certainty. As we have demonstrated, complete certainty is something to be given to some very special beliefs, at least to begin with.

The conclusion of the meta-sceptical argument above is that since one could always be wrong about proposition $p$, it follows that one can revise $p$. The statement $\forall p. Rp$ for revision operator $R$, is a way to formalise this in logic. It turns out to be itself revisable like this: $R(\forall p. Rp)$ And it turns out to not lead to contradictions [CITATION OF LOGIC OF QUINEAN REVISABILITY]. This means that in the future, as we approach the logical theory of the world (a notion which will be formalised shortly) we can revise beliefs with universal revisability. It could end up being the case that not every propositions is revisable, but we don't currently know which propositions those are yet. We will give example of one such proposition in the next section.

## Cartesian scepticism

Cartesian scepticism is even more extreme than the argument from error, since it questions our ability to form knowledge what so ever. They generally consist of a class of sceptical scenarios which are meant to question our knowledge in very profound ways. Examples include being a brain in a vat, the dream of a butterfly, being fooled by an evil demon etc. There have been many responses to this class of sceptical scenarios and their implication on knowledge.

One possible way to answer to these sceptical scenarios is an appeal to phenomenology. Despite all possible sceptical scenarios, something seems to exist, the experience itself. There at least exists some set of pure phenomena, formalizable as a set of experiences $E_@$ which are happening right now. The set has as members the visual field, auditory field etc. Future posts will formalise this notion more precisely. However, we do not posit an "I" or an personal identity yet, we are still sceptical of that for now. Similar proposals have been made by for example William James or Edmund Husserl (Sources). When taking this into account, we don't fall into the cartesian trap of stating "I" exists because there is no "I" in the period of theoretical bracketing, only pure experience. It's not "I think therefore I am", it's "There's an experience, therefore something is". So the following statement seems to be certain:

**There exists an experience**

Or formalised in logic:

Let $E$ be the set of experiencing in the universe and $E_@$ reference the current, ongoing experience (you reading this!).. This set is nonempty.

$|E|>0$ 

Alternatively

$\exists E_@\in E$ 

We will not immediately give up universal revisability for the statement does contain the controversial statement "exists". I do however, given Quine's criterion of existence, believe with certainty that any theory of the world will predicate over $E_@$, or at least the microphenomenal experience (which will be explained in a future post) that $E_@$ is composed by. 

One can then start to create objects and propositions in the language of phenomenal experience which seem to be true (or at least possibly true, if our cognitive capacity to recognize the truth of some phenomenal sentences isn't entirely correct) even if we are in a simulation, dream, or vat. Subsets of various phenomenal spaces, such as a region $A$ inside of visual space, and propositions about such regions such as "Region $A$ in $E_@$ is RED" are true or false depending on it's really the case that region $A$ in $E_@$ is RED. Such statements I call "phenomenal propositions" and the language they make up is called the "phenomenal language". A future post will explicate this notion more, and how it can help solve scepticism, how to formalise the language of phenomenology into set theory, and how to deal with Sellars myth of the given.


Global scepticism is also self-defeating in the sense that on takes to know the proposition "No proposition p is known", which is clearly self-defeating, since there now is an example of a proposition $p$ which is known.

A quick-fix is to reformulate it too "No proposition $p$, except this one, is known"  

## Agrippa's Trilemma

Agrippa's trilemma, and the accompanying Pyrrhonian scepticism towards justification, the difficult choice on how to create a justification structure, is usually solved by denying one of its three premisses: Either you accept that there exists unjustified beliefs (foundationalism), circular reasoning (coherentism) or infinite chains of reasoning (infinitism). 

We will instead take the rather radical approach of both coherentism and foundationalism, in the sense that we work with coherentism as a working hypothesis, but over time revise our beliefs so as to eventually find a description of the world with axioms that can perfectly describe, explain and predict the world. In the limit of inquiry, this is the theory that most likely will come into fruition. This takes inspiration from universal revisability, as described above, while still allowing a compressed axiomatic description of the world to "unfold" over time, and as the axioms are "justified" empirically rather than from supposedly "intuitive" and "certain" starting points the way rationalist foundationalists propose. 

The last section gave us a useful tool for characterizing empiricist foundationalism, by taking "blobs of experience" into set theory. As can be seen with non-linearities in visual space[source], IIT set theory [source], hyperbolic smell [source] and logarithmic hearing [source]. If visual space happens to be discrete, then the 'pixels' could actually be hexagonal[source] and Barry smith's formalism of continuous visual space and mereology instead [source]

That set theory has been so neglected by empiricists is saddening, although it will be applied here fully in formalising something similar to empiricist foundherentism. 

While it might seem as if we're approaching an experientialist pure fallibilistic strong foundationalism, it's not so easy. Consider Sellars the myth of the given. He claims that truth claims of sense experience does not imply knowledge $\neg (X(U)\rightarrow K(X(U)))$ 
Where $X$ is experience and $U\subseteq E$. 

It is also the case that beliefs about memory for example could justify beliefs about earlier experiences. This means that it is not foundationalist but foundherentist as justification can go in two directions. We're also obviously using our beliefs of set theory to formalise this entire system as well. 

The graph structure of justification looks like the coherentism one, but in the limit of inquiry, approaches the foundationalist view. 
(Images here maybe?)

So now we need to define a belief set, a belief revision, a working description of the world, and the complete description of the world. 

![[Pasted image 20230329214529.png]]
Imagine the following coherentist justification structure pictured in blue and a foundationalist one pictured in red. Blue arrows represent inferences using defeasible reasoning and red represents certain reasoning. Let's eventually say that 5 and 4 justify 12, such that we get the following picture
![[Pasted image 20230329220323.png]]

Then we can claim to have a theory of the world, call it $T_0$ which contains 12 as an axiom and 13 as a logical consequence. Over time we want to de-muddle the circular system until it can be entirely replaced by a foundationalist system to describe the whole world in the limit of inquiry.

![[Pasted image 20230329222401.png]]

Source: Graph structure in angrippas trilemma or whatever it was called

![[Pasted image 20230608224717.png]]
Coherentism looks like this actually!
Yellow: Not very coherent
Green: Very coherenent
Beliefs mutually support eachother


But it could be divided up into multiple smaller theories which are in turn coherent as a whole.
Three theories:
1. General Relativity
2. Aether Theory
3. Falsification and hypothesis testing

Then we have
![[Pasted image 20230608225404.png]]

As a whole they are very coherent. The meta-level would be green. 
However, a problem might be noticed which is a problem to all theories of coherence. There's no grounding in experience. So experiments would just be beliefs. One might aswell have been constructing fictional theories. 

Now what about observations. Theory ladeness?

Coherentism has problems: 
Drunken sailors argument, beliefs themselves can't uphold anything.
The content determination thesis has impossibility results (coherence is not truth conducive). 
Gets you weak empiricist foundationalism.

Recent results in formal epistemology have shown that coherentism is not truth conducive without singular beliefs being atleast somewhat reliable. [Coherentist Theories of Epistemic Justification (Stanford Encyclopedia of Philosophy)](https://plato.stanford.edu/entries/justep-coherence/) Which means weak foundationalism is necessary.

That's were foundherentism comes in!


Foundherentism is very similar to Quine's web of belief.

![[Pasted image 20230610212624.png]]
The white one's outside the green are observations, not beliefs, which is why this differs from coherentism where justification is purely beliefs. But it's different from foundationalism since justification is in the mutual coherence of the entire system rather than purely the observations. 

Beliefs closer to the centre are those which are logical, or about the foundherentist system of belief itself. 

So to define it formally, a web of belief $W=(R^*, B, E)$  where $R^*$ is a set of coherence relations, $B$ is a set of beliefs and $E$ is a set of experiences. 
So for example, $R\in R^*$ which is $R\subset B\cup E\times B\cup E$.

Question: Credence or accept/reject states? It seems like the book on coherence as a coherence relation weight value maximization algorithm only puts beliefs in accept or reject while Bayesian coherence takes beliefs to have credence's. 

Now for the formalisation of belief revision. 

A belief state is a set of propositions $\{p_1,\dots p_n\}$ for some beliefs $b_i$ together with a value representing conviction or certianty. This generates a set containing ordered sets of beliefs and it's certianty value $\mathbb{B} = \{(p_1,c_1),\dots (p_n, c_n)\}$. We will call $c_i$ the credence of belief $b_i$. We then create a justification structure as a directed graph $G \subset \{(b_i, b_j) \in \mathbb{B}\times \mathbb{B}| i\neq j\}$. We take $i\neq j$ because beliefs don't self-justify. 

Then there exists some belief revision tool. We will not yet discuss which belief revision tool to be used, but some that can be used is for example hempelian confirmation, Hypothetico-deductive method, Bayesian updating, AGM updating, NARS (non-axiomatic reasoning system), coin flipping e.t.c. We will currently generalise all systems of belief updating as an function $u : \mathbb{B}\times E \rightarrow  \mathbb{B}$ which generates a new belief set from an old one given evidence set $E$ which is a set of experiences.  

Being sceptical means having high belief entropy, that is too say, all competing beliefs have a roughly 0.5 credence. While a low entropy state would be very high credence on one belief while beliefs inconsistent with the high credence belief have low credence. 




It turns out that axiom 2 is justified by every observations, and cannot by definition be justified by observation.  Axiom 1 is justified by all other beliefs. 

After that we can have a compressed belief system. Maximum compression can be seen as a foundationalism. 
11 axioms of ZFC
3 postulates of GR
5 postulates of QM
5 axioms of IIT
alt. GR+QM+IIT in the language of ZFC.




The rest of this chapter will formalise the foundationalist theory (the red) and a future chapter will formalise the coherentist theory (the blue).


There is also infinitism, in which case you could have either an actual infinity of justification or an potential infinity:
For every belief $b$ there exists justification $j$ such that $j$ justifies $b$
Or
For every belief $b$ one can use that belief to create a justification $j$ such that $j$ justifies $b$

But that is wrong

## Formalising the theory that describes the world

This section focuses on the formalization of such a theory that describes the world once it has been reached. It is naive to believe that we have such a theory right now, for reasons that will be discussed in [[2. The logical structure of the world]], so we will talk in very abstract terms about this theory and formalize the axioms that have been derived in earlier sections. We will also formalise our "working theory" of the world, as we develop it through the book we'll add and maybe remove axioms based on AGM updating. This will be our currently best theory of the world, before the theory that describes the world is found (if it even can be found).

Let the theory that describes the world be $T_\omega$ = $\{A_1,\dots, A_n\}$ for $n$ axioms in that theory stated in the language $L_\omega$. We also define our working theory of the world $T_i=\{A_1,\dots, A_k\}$ for $k$ axioms where $i$ stands for iteration written in language $L_i$. Everytime AGM updating is performed, we develop $T_{i+1}$.  This is of course unless inductive reasoning is necessary to justify an axiom in $T_\omega$ (?). The set of all logical consequences of a theory $T$ is written as $C(T)$. A proposition $p$ is derivable in $T$ iff $p\in C(T)$, also written as $T\vdash p$. Source: Metaphysics (the book).

The function of the working theory is to formalise as much of the belief set as possible. To prevent various situations we will have to provide some restrictions to the working theory.

1. Ensure that as few axioms are used as possible (occam's razor restriction) so as to prevent the working theory to just be one's entire belief set. This is related to compression and algorithmic information theory, which will be discussed in [[2. The logical structure of the world]].
2. To generate as many propositions in the belief set as possible with credence greater than 0.5 (or some other set value). 
3. Utilizing underlying sceptical methodology. 

For out working theory $T_0$, given our earlier discussions on scepticism, only contains two axioms:
$A_1 =\forall\phi J\phi$ (Universal Revisability)
$A_2 = \exists E_@\in E$ (Self-Existence)

We will formulate which derivation rules in [[2. The logical structure of the world]] where we explore the various problems of such a theory, such as if a complete description of the world can be contained in the world and solutions to such a theory and Russell's paradox, Putnam's paradox, Gödel's Incompleteness theorems and other problems and potential solutions.

The goal of this book is to generate a highly developed working theory with axioms that generally cover most beliefs upholding to the theoretical restrictions. 

## Counterargument: "But such a theory doesn't exist"

Uh no, it has to exist. One way to generate a theory about the world is to create a theory $T_\omega$ such that every single proposition that is true is an axiom in $T_\omega$. This theory would then obviously be a theory that describes the world. The problem? It is epistemologically inaccessible. This is because propositions regarding every fact about the way the theory itself is written down would be contained within the theory. This is so far not paradoxical, see it as a set of propositions that describes for example how every atom is laid out on the paper where $T_\omega$ is describing it's own atomic structure. This is impossible to do. Even using say, electrons to store $T_\omega$ in some binary language that uses, say, the up and down states of the electron to store the binary translation of $T_\omega$ would have to be describing their own states, which requires referencing themselves in the process. This clearly doesn't work. 


## Epistemic access to $T_\omega$

As we discussed last section, even if $T_\omega$ exists, one can never come to know it. We will always have remnants of justificatory circularity without ever accessing a $T_\omega$. Or that if we did reach a $T_\omega$, we couldn't verify that fact. 

Kant argued that even if such a theory, atleast the one's that includes a description of 'noumena' (what is beyond experience), cannot be known, even if it exists. So if $T_\omega$  predicates over objects which don't have phenomenal properties, then one can never know of the existence of that object. Similarly, objects with both phenomenal properties and non-phenomenal properties it will be unknowable to know which non-phenomenal properties the object has. 

This is a worry I do have. Let's assume this is the case. This means $T_\omega$ does not contain epistemic axioms, i.e axioms that contain epistemic terms such as "knowledge", "justification", "rationality" e.t.c. In such a scenario, $T_\omega$ does not tell you how to know or justify the rest of the theory. 


## Gödel's Incompleteness Theorem

Someone is bound to mention this as a counter-argument so I might as well address it shortly here although I will not deal with logic deeply in this chapter. $T_\omega$ could possibly contain the same or greater level of expressibility as Robinson arithmetic, which allows for a Gödel numeration, which allows for self-referential statements of provability, which leads to incompleteness and inability to prove it's own consistency. That the theory which describes the world has the same or greater level of expressibility as Robinson arithmetic is however up for debate. It could absolutely be the case that such a theory has strictly less expressibility, in which case it could be complete, even provably complete. 

Max Tegmark has made similar remarks on this, as he states "that only Gödel-complete (fully decidable) mathematical structures have physical existence. This drastically shrinks the Level IV multiverse, essentially placing an upper limit on complexity, and may have the attractive side effect of explaining the relative simplicity of our universe.". He even claims that the universe "could in principle contain observers capable of thinking about Gödel-incomplete mathematics, just as finite-state digital computers can prove certain theorems about Gödel-incomplete formal systems like Peano arithmetic".

[Mathematical universe hypothesis - Wikipedia](https://en.wikipedia.org/wiki/Mathematical_universe_hypothesis)

## External world scepticism

The working theory of the world $T_0$ vocabulary does not contain any non-mental properties, nor non-mental objects, since both belief revision and experience are both mental objects. This does not rule out that say $T_\omega$ is a physicalist or dualist theory, but we have not currently found a way to translate the axioms of $T_0$ into only a physical properties. But does anything outside of the mental exist? This is a long standing sceptical problem which will be discussed in this section. 

External world scepticism does not have to rely on cartesian scepticism for justification, the indistinguishability between an existence and non-existence of an outside world is enough.  
[An Argument for External World Skepticism from the AppearanceReality Distinctio.pdf](file:///C:/Users/offic/Documents/Books/Philosophy/An%20Argument%20for%20External%20World%20Skepticism%20from%20the%20AppearanceReality%20Distinctio.pdf) . Since we cannot distinguish between a scenario when we really hands and when we're simulated/parts of a dream/brain in var etc. without actual hands but merely the perception-of-hands, then we don't know. This is the main principle of Kripke semantics for epistemic logics after all. 

The indistinguishability implies
$\neg K\exists x W(x)$

However we know that it is possibly exists
 $K \diamondsuit\exists x W(x)$

The reason that the external world being false would be indistinguishible is that our phenomenal experience is underdetermined by the hypothesis that there exists an outside world and, for example, brain in a vat or being in a dream. And if you're like Dennett [source thta book] and for some reason believes that such a sceptical scenario needs to take place under the assumptions of modern physics and plausibility of future human civilization, then Nick Boström [source that paper] makes a decent case for there being a surprisingly high probability for some future superintelligent AI or post-human civilization (or some combination of both) performing ancestor simulations by using mega-computers built as a Dyson sphere around stars. Such a massive installation could easily simulate a human mind if the human mind is simulable. 

However, "Famous arguments by Putnam [23] and Chalmers [8] suggest that even if we were (in some sense) brains in a vat, our ordinary beliefs about the external world would still be true (but merely about the simulated vat world), considering this hypothesis should not motivate skepticism about ordinary claims involving the external world"[External World Skepticism, Confidence and psychologism about the problem of priors.pdf](file:///C:/Users/offic/Documents/Books/Philosophy/External%20World%20Skepticism,%20Confidence%20and%20psychologism%20about%20the%20problem%20of%20priors.pdf). Likewise, science could still build models over how the simulation work and perform experiments within the simulation. 

A common semantic argument is that words no longer refer to objects that really exists "out there", which in some way invalidates reason, semantics and truth value of statement regarding ordinary objects. This is clearly not true if we're referring to simulated or experiential objects. 

What is true no matter if external world is true or not? Not just the language of phenomena,  but also a set theory of phenomena, for example as can be seen in the image. This will be vastly expanded upon in future chapters, but until then take a look.
![[Pasted image 20230301111511.png]]

A common class of arguments against external world scepticism are usually known as Moorean responses to external world scepticism. But common sense is very often wrong. Intuition is often wrong. Intuition is radically subjective. "Obviousness" does not justify. Moorean arguments rest entirely on "intuition" and "common sense", which does not imply that a statement is true, and can often be completely wrong or radically relative between people, culture, time, scientific progress and so on. 

Using our best scientific theories to justify it doesn't work either (the abductive response). Imagine infinite number of modes. "Physical substance best explains out scientific models" Well then we create a new substance A defined to be that substance which best models our scientific models and is non-physical. B can be defined likewise, with added condition "not like A" etc. 

However, as $T_\omega$ could still include non-mental properties and objects, despite there currently being poor arguments for it, we will still formalise it but not yet accept it into $T_0$. Let $M$ be a mental predicate, then the axiom states that there exists an object such that it is not mental:

(External world) $\exists x\neg M(x)$

## Solipsism and the problems of other minds

A consequence of radical scepticism is that, while it is non-revisable that there exists an experience, the same cannot be said for experience outside of that. 

It seems that the theory of the world $T_\omega$, if solipsism is actually true, would only describe one's direct experience. But if solipsism is actually false, then that opens up some interesting avenues. This means that $T_\omega$ will contain the necessary axioms to justify the falsity of solipsism, i.e 

$T_\omega \nvdash !\exists E_@\in E$

However, one can take it to exist "subminds", which is the powerset of all microphenomenal experience of $E$. That is to say $P(E)$. If we take an $x\in P(E)$, this corresponds to some "pixel" in our visual field for example, or some pitch-decibel combination in the auditory field. This will be formalised in [[3. Formal Phenomenology]]. This will also be discussed in questions about overlapping minds in some forms of panpsychism.


If external world scepticism is true, but solipsism is false, then content externalism works for referencing non-experienced experiential objects/properties.  

Dogmatic working theory of the world

$T_i^* = T_i\cup \{\neg!\exists E_@\in E, \exists x\neg M(x) \}$

However there can be different configurations of the truth value of the scepticisms. 

| |Solipsism true|Solipsism false|
|-----|-----|----|
|**External world true**|Alone in the world, everyone else is a p-zombie|Ordinary realism|
|**External world false**|You are the Universe|Only observers, similar to Berkleyan idealism|

# Conclusion

Radical scepticism is solved by radical empiricism, aswell as foundherentism and taking the theory of the world concept not to litteraly(?).

We've thus been able to generate a logical theory of the world $T_0$ with the following axioms:

(Universal Revisability) $\forall p. Rp$
(Experience existence) $|E|>0$

With different kinds of dogmatic versions including
(Non-solipsism) $T_0^* \nvdash !\exists E_@\in E$
(External world existence) $\exists x\neg M(x)$






## The problem of the criterion

Particularism where we generate a list of taken for granted propositions, formalise it in some system, and the truth in that system there is the criterion. 


## Occam's Razor

The theory of the world $T$ should have as few axioms as possible. The consequences don't matter at all. Each axiom is like a lightswitch, that can be turned on or off at will and the conequences can be tested. If a very small number of axioms yield a lot/infinite number of theorems, then that is fine, and does not violate occam's razor. What would violate occam's razor would be adding axioms beyond necessity, unjustified or poorly justified axioms. 

This obviously entails a finite set of axioms. An infinite axiomatization, such as that of Peano Arithmetic, would highly violate occam's razor. That there has to be an infinite induction schema to describe the universe would require a very large amount of justification for why we couldn't have a finite set of axioms.  

--Above might be very wrong--

Occam's razor as ontology minimization
Occam's razor as Kolmogorov complexity minimization

Occam's razor as some kind of minimization. Just like coherence maximisation hmm. 
The semantic theory of structure of scientific theories: Minimize number of theories? Does the syntactic one minimize the number of axioms? What about the pragmatic one? Minimum number of beliefs for goal achievement?


## Against Intuition and for Radical Empiricism

Let $p$ be a proposition. $p$ is believed intuitively iff belief in $p$ is not caused by any reliable process and belief in $p$ is not a logical deduction and belief in $p$ is caused by a "feeling" of "rightness". As a naturalist, I'm invoking psychology to explain the phenomenon of "intuition". $p$ is justified by the brains quick processes which evolved to sense danger, disgust e.t.c. This quick process is usually wrong, but can be a great starting point for further investigation.

Moral intuition, as an example, is no more than the emotion of disgust applied to certain actions or states of affairs. This does not entail that moral facts don't exist, just that moral intuition is not the justification process for them.  

Another example is mathematical intuition. When I see a math problem for example, I might get an "mathematical intuition" on the general gist of how to solve it. I'm often wrong, but not always, and the slow brain must activate to actually justified the mathematical statement p by logical deduction. Ethical intuitions is merely a disgust/approval psychological attitude towards an event or action, and tells nothing true. Same with religious intuition. Definitions aswell, like "a chair is defined to be that which has four legs", intuitive but never true.

This is not to say intuition cannot ever be used as evidence, it could be used in physchology for example. A general psychological theory on what and why certain poeople find some ideas as intuitive and other ideas as non-intuitive could be investigated and analysed empirically, an idea proposed by Chomsky (SOURCE, hintikka 1999). But no intuition ever justifies statements in any subject. 

An interesting consequence of rejecting intuition is that a priori justification is also rejected as a consequence, as long as we can agree that the only way to justify a priori if with intuition (if other ways exist, I am not aware of them). This means that all statements, wheter they are mathematical, logical, or philosophical, and so on, are justified a posteriori. They are justified completely based on experience and nothing else. This yields radical empiricism as a result. 



## Theories of the world with equal empirical derivations/Underdetermination

Let's say there's $T_i$ and $T_j$, such that $T_i\neq T_j$ and both describe the universe. Then we'd have a type of underdetermination of theories. Then we lett a class $C=\{T_1,\dots,T_n\}$ be the set of equally good theories of the world. Any other theory would be worse. This is just fine.

One way one could still select between theories is the "simplest" one, which could for example be defined as the smallest computer-program which could encode the theory. (SOURCE: Algorithmic complexity theory paper).


There could be multiple theories $T_1,\dots T_n$ such that they all seem to be the best compression. However the theories would still analyze some fundamental structure

## Conclusion






# Varied ideas


# Solutions to Radical Scepticism




## Moral scepticism

Moral intuition doesn't justify.



## HD-confirmation and Bayesian Reasoning



Both sind gruSS güt jawhol?


Two potential formalism for belief revision are HD-confirmation and bayesian updating. 


# Varied ideas

Sorities Paradox?

Justifying justification? Problem of the criterion
Nah I'll go by uhhhhh reliabilism?

## Models, Kripkenstein and Semantical scepticism

A model $M$ contains a domain and an interpretation function for a theory. In this metaphysical sense that we're talking about theories here, $M_\omega$ is the modell for the description of the world and thus it's domain will contain every single object that actually exists. Because such a set is a subset of the world, we can never express this set (atleast not extensionally, maybe intentionally). This way, the objects we refer to when we talk about objects is in this set or the powerset e.t.c. 

The problem comes when this becomes ambigious. For example, let's sa

Meaning and semantics
Quaddition
Scepticism and externalist semtantics

Brain in a vat. Dennet's argument of cascading complexity is false because a superintelligence need only simulate sense experience of sand falling through hand and fooling you. 


![[Pasted image 20230322170326.png]]

The problem of other minds: cannot be reasoned inductively, only abductively. For accounts on abduction whereby it is reducible to abduction, unless there is some kind of transcendental deduction to know other minds (Kant would say it's impossible), then one can never know other minds. Experiments: One can enhance and edit oneself in such a way to experience more sense-datum. One can analyse this using data to eventually develop a scientific theory of consciousness and it's material correlates. 

Imagine Anna who studies everything about color and it's physical substrate but doesn't know what it is like to experience red due to being stuck in a black and white room. What if she was able to, with her knowledge about the brain, create a machine connected to her brain that induces teh color of red? This could be another great start to solving the problem of other minds, the hard problem of consciousness, and the mind-body problem. Would be quite the case for physicalism aswel. 



## Removed from the section on external world scepticism, might be a bad section

We will continue our bracketing of all theoretical systems outside direct experience. Other types of scepticism like space and time itself is put into question. Our current understanding in physics cannot be used here, that understanding of space and time is almost certiantly not $T_\omega$ mostly due to the fact that quantum mechanics and general relativity don't share one axiomatic foundation. Let alone phenomenal experience (neither theory predicates over, for example RED, not talking about baryonic colour charge of quarks during the strong interaction, but the phenomenal experience itself, unless once accepts some kind of physicalist panpsychism where the property baryonic color charge happends to line up with the phenomenal experience of color, but the theories of quantum mechanics nor the standard model itself says nothing about that). A longer discussion on scientific realism vs anti-realism will be on a future post. 



## Calculating Coherence



