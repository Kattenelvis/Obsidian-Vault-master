For my university course look here [[Decision Theory (Course)]]

\<idea> 
Dynamic Decision theory. Assume a subjective interpretation of probability theory, such that the probabilities indicate credence/belief. Then for any lottery $L$ these credences would update over time as new information was gathered about $L$ aswell as new possible actions and outcomes being discovered. This could update forever as there's always a diminishingly small chance that one is wrong about $L$. At what point is it the most rational to stop and take the best option? An maximiser might keep going forever, especially among two almost identical options (Burundian's ass moment) but a satisficer can pick the best after just a short while. 


<idea/>


"[Frontiers | Neural Signatures of Intransitive Preferences (frontiersin.org)](https://www.frontiersin.org/articles/10.3389/fnhum.2010.00049/full)"
"It is therefore tempting to speculate that intransitive choices are not the consequence of a noisy implementation of independent and hierarchically organized preferences ([Hey, 1995](https://www.frontiersin.org/articles/10.3389/fnhum.2010.00049/full#B28) ), but may reflect truly context-dependent, intransitive valuation. This view is corroborated by the fact that activity in several value-coding brain regions incl. DLPFC and striatum, correlated with the individual degree in the propensity to make intransitive decisions."




## Causal Decision Theory
Two-boxers, HOWEVER:
"A way of reconciling the two sides of the debate about Newcomb’s problem acknowledges that a rational person should prepare for the problem by cultivating a disposition to one-box. Then whenever the problem arises, the disposition will prompt a prediction of one-boxing and afterwards the act of one-boxing (still freely chosen). Causal decision theory may acknowledge the value of this preparation. It may conclude that cultivating a disposition to one-box is rational although one-boxing itself is irrational. Hence, if in Newcomb’s problem an agent two-boxes, causal decision theory may concede that the agent did not rationally prepare for the problem. It nonetheless maintains that two-boxing itself is rational. Although two-boxing is not the act of a maximally rational agent, it is rational given the circumstances of Newcomb’s problem."


"Causal decision theory may also explain that it advances a claim about the evaluation of an act given the agent’s circumstances in Newcomb’s problem. It asserts two-boxing’s conditional rationality. Conditional and nonconditional rationality treat mistakes differently. In contrast with conditional rationality, nonconditional rationality does not grant past mistakes. It evaluates an act taking account of the influence of past mistakes. However, conditional rationality accepts present circumstances as they are and does not discredit an act because it stems from past mistakes. Causal decision theory maintains that two-boxing is rational, granting the agent’s circumstances and so ignoring any mistakes leading to those circumstances, such as irrational preparation for Newcomb’s problem."


Positivists don't like it becuase they don't believe in causality. Or atleast, they don't believe causality is a meaningful concept. 



Completeness in preference relations

[Conflicting Reasons in the Small-Improvement Argument](https://johanegustafsson.net/papers/conflicting-reasons-in-the-small-improvement-argument.pdf)


