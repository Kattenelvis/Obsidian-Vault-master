Would Kantians be EDTers?

EDT implies one ought to act morally: If I do something that is good for the overall rather than slightly better for me but much worse for others, that gives me evidence that others act in this way, and that's bad for me. Instead I ought to act rationally according to EDT.

Therefore, I will to make EDT universal law? 



For my university course look here [[Decision Theory (Course)]]

\<idea> 
Dynamic Decision theory. Assume a subjective interpretation of probability theory, such that the probabilities indicate credence/belief. Then for any lottery $L$ these credences would update over time as new information was gathered about $L$ aswell as new possible actions and outcomes being discovered. This could update forever as there's always a diminishingly small chance that one is wrong about $L$. At what point is it the most rational to stop and take the best option? An maximiser might keep going forever, especially among two almost identical options (Burundian's ass moment) but a satisficer can pick the best after just a short while. 


<idea/>


"[Frontiers | Neural Signatures of Intransitive Preferences (frontiersin.org)](https://www.frontiersin.org/articles/10.3389/fnhum.2010.00049/full)"
"It is therefore tempting to speculate that intransitive choices are not the consequence of a noisy implementation of independent and hierarchically organized preferences ([Hey, 1995](https://www.frontiersin.org/articles/10.3389/fnhum.2010.00049/full#B28) ), but may reflect truly context-dependent, intransitive valuation. This view is corroborated by the fact that activity in several value-coding brain regions incl. DLPFC and striatum, correlated with the individual degree in the propensity to make intransitive decisions."




## Causal Decision Theory
Two-boxers, HOWEVER:
"A way of reconciling the two sides of the debate about Newcomb’s problem acknowledges that a rational person should prepare for the problem by cultivating a disposition to one-box. Then whenever the problem arises, the disposition will prompt a prediction of one-boxing and afterwards the act of one-boxing (still freely chosen). Causal decision theory may acknowledge the value of this preparation. It may conclude that cultivating a disposition to one-box is rational although one-boxing itself is irrational. Hence, if in Newcomb’s problem an agent two-boxes, causal decision theory may concede that the agent did not rationally prepare for the problem. It nonetheless maintains that two-boxing itself is rational. Although two-boxing is not the act of a maximally rational agent, it is rational given the circumstances of Newcomb’s problem."


"Causal decision theory may also explain that it advances a claim about the evaluation of an act given the agent’s circumstances in Newcomb’s problem. It asserts two-boxing’s conditional rationality. Conditional and nonconditional rationality treat mistakes differently. In contrast with conditional rationality, nonconditional rationality does not grant past mistakes. It evaluates an act taking account of the influence of past mistakes. However, conditional rationality accepts present circumstances as they are and does not discredit an act because it stems from past mistakes. Causal decision theory maintains that two-boxing is rational, granting the agent’s circumstances and so ignoring any mistakes leading to those circumstances, such as irrational preparation for Newcomb’s problem."


Positivists don't like it becuase they don't believe in causality. Or atleast, they don't believe causality is a meaningful concept. 



Completeness in preference relations

[Conflicting Reasons in the Small-Improvement Argument](https://johanegustafsson.net/papers/conflicting-reasons-in-the-small-improvement-argument.pdf)




file:///C:/Users/Katte/Downloads/the-value-of-risk-in-transformative-experience.pdf

½ If we accept that chances can have non-linear value, either generally or in cases
involving constitutive risk, we have to reject an assumption of EUT based on the
vNM framework, chance instrumentalism (CI), which says that rational agents should
be indifferent between getting something for sure and a gamble with equivalent
expected utility. According to CI, chances only have value insofar as they give an
agent the chance to obtain some good – they do not have any value independent of
the good (Stefánsson and Bradley 2015: 603). Stefánsson and Bradley prove that CI
and the principal principle together result in linearity about the value of chances, so
one must be rejected. The principal principle, introduced by Lewis (1980) concerns
the relationship between rational credences and chances. If the evidence suggests that
some outcome has a 5% chance of occurring, then a rational agent ought to set their
credence at 0.05 in line with the evidentially supported chances. The principal principle
is intuitive, widely accepted (in various forms), and plausibly a requirement of ration-
ality, so I reject CI in line with Stefánsson and Bradley




