





Rule following paradoxes?
Major responses: Error theory, Reductionist dispositionalism, anti-reductionist "the paradox is an illussion".
The death of pragmatics?



In the movie "blah" the aliens have a special language with a ring. While we will probably not utilize the language as a way of "time traveling" through our 4D worm, we can still end up having very new ways of communicating in the future.

For instance, in Kripke's paradox, blah blah explanation. 

Here we can see that pragmatics play a big role in determining whether or not quus means 42+64=5 at some point. But with mathematical codes as a new language of the future, that may no longer be a thing. 

While it may be the end of pragmatics, and that a fully semantic language can be utilized instead between agents using mathematical protocols.

LLM's however, are decent at picking up pragmatics as of 2024-03-22. For instance, if you write "wow I truly adore that I have to endure this job every day!" I get this:

Me: "wow I truly adore that I have to endure this job every day!" Using your knowledge of pragmatics, is that a sarcastic sentence or not?


ChatGPT: Yes, based on the typical usage of language and the context provided, it's likely that the sentence is being used sarcastically. The phrase "I truly adore that I have to endure this job every day!" suggests a level of frustration or dissatisfaction with the job rather than genuine admiration. In everyday conversation, sarcasm often involves saying the opposite of what one truly means, and in this case, the speaker is expressing discontent with their job despite using positive language."

So pragmatics may not die. However as syntactic symbols such as /s is used on the internet as an [tone indicator] to indicate sarcasm, there may be no need for pragmatics if even syntax can handle it. In either case, negating a proposition is pretty much the same thing.

$p, /s\leftrightarrow \neg p$ 



# Natural Language processing

Predictive modeling, markov chains



# Transformer Architecture



[2304.10557](https://arxiv.org/pdf/2304.10557)
[web.stanford.edu/~jurafsky/slp3/9.pdf](https://web.stanford.edu/~jurafsky/slp3/9.pdf)

Self-attention/multi-head attention

> Attention can be thought of as a way to build contextual representations of a token’s meaning by attending to and integrating information from surrounding tokens, helping the model learn how tokens relate to each other over large spans.

![[Pasted image 20241206161040.png]]

Each block is a multilayer-network. It is a multi-head attention layer, feedforward networks and layer normalization steps. 

"At the center are columns of transformer blocks. Each block is a multilayer network (a multi-head attention layer, feedforward networks and layer normalization steps) that maps an input vector xi in column i (corresponding to input token i) to an output vector hi. The set of n blocks maps an entire context window of input vectors (x1 xn) to a window of output vectors (h1 hn) of the same length. A column might contain from 12 to 96 or more stacked blocks."

"The columnofblocks is preceded by the input encoding component, which pro cesses an input token (like the word thanks) into a contextual vector representation, using an embedding matrix E and a mechanism for encoding token position. Each column is followed by a language modeling head, which takes the embedding out put by the final transformer block, passes it through an unembedding matrix U and a softmax over the vocabulary to generate a single token for that column."
## Big Data
Scrapping big data from the internet, enormous data-bases to train on, scaling laws


# Large Language Models







Old blog post idea:

**What AI can teach us about language

  

How do we learn language? Do we learn it through repetition with rewards and punishment, or do we have innate tools for building grammar? The first account can be called the Behaviourist school of thought, mostly founded on the theories of psychologist B.F Skinner. The second can be called Chomskyian, named after linguist Noam Chomsky who proposed a theory of universal grammar and the minimalist program. This question might be answered by which AI technology will solve the Turing test.

  

The Turing Test, also known as the imitation game, is a scenario involving two people and one bot. The bot and one of the humans chat with the second human, and if the second human cannot distinguish between who is the bot and who is the human, the bot passes the Turing test.

  

People started to attempt creating these kinds of bots, but at first they were rather basic with a bunch of “if then” statements but has since expanded into full fledged semantic-parsing bots such as Alexa by Amazon or Siri by Apple. There have been serious developments of conversational AI in the last few years, especially in the field of natural language processing since AI as a whole has exploded in popularity, especially as computers have gotten more powerful and huge datasets have been gathered.

  

There are two major types of natural language processing: Symbolic and Neural. Symbolic used to be dominant, but has been superseded by the neural type. The symbolic can be explained as a system where the bot is programmed by the programmers exactly how it should parse the grammar and exactly how it should respond in response to input from the user. It is the original approach of multiple "if, then" statements, for example, if the user inputs "who was the first person to walk on the moon?" the computer would parse it using if else statements and after pre-established grammatical rules to then build a reply to send to the user using the same rules. The problem with this approach is that the bot is really dumb, and only workes in narrow confines that the programmers set up. 

  

The statistical, neural network approach to conversational AI has been developed rapidly in recent years. It uses large sample sizes of data to train on to minimise a loss function via a backpropagation algorithm that updates the neural net depending on rewards and punishments. This is atleast what reinforcement learning is about, which is the technology most modern natural language processing uses. [SOURCE]

  

Now this lends into an interesting philosophical question that goes straight into the behaviourist vs chomskyan approaches in the philosophy of linguistics. If an AI that passes the Turing test learns all the grammar based on a reinforcement learning algorithm with no pre-built symbolic based approaches, would this support the behaviourists side? Or conversely, if it would be necessary to have a hybrid approach as discussed earlier for the AI to pass the Turing test, would this support the chomskyan side of the existence of universal grammar? What about the necessity of inborn/innate knowledge and tabula rasa theory? 

  
  
  
  

Noam chomsky in the book “The minimalist programme” he lays out the following foundations for the project of universal grammar: 

  

“The language faculty has an initial state, genetically determined; in the normal course of development it passes through a series of states in early childhood, reaching a relatively stable steady state that undergoes little subsequent change, apart from the lexicon. To a good first approximation, the initial state appears to be uniform for the species. Adapting traditional terms to a special usage, we call the theory of the state attained its grammar and the theory of the initial state Universal Grammar (UG)”

  

This bears some resemblance to the idea of symbolic manipulation discussed earlier. If symbolic manipulation has not worked for AI, how come it works for humans? 

  
  
  
  
  

To begin answering this question, we first need a theory of what language really is. If language is constructed a certain way, it could indicate both how humans learn/use language and how AI uses it. When I'm writing in a language, I'm performing a cognitive process that turns thought into words. A cognitive process is also a conscious process, in the sense that I'm actively attending to the process, and I'm experiencing it in my inner voice. This leads to my first important thesis: language is a conscious process. Language without consciousness is contradictory, since language itself is a conscious process. 

  

Since I also take in information from my surroundings to perform cognitive tasks, i.e I cannot do cognitive tasks without stimulus of some kind. This viewpoint is known as extended cognition and if true, would mean that bots also experience stimulus of some kind. This is because it is necessary for them to experience something to even be able to cognize and perform an output action. This is true even for computers without any sensors, since it’s all some kind of sensory information at the end of the day. 

  

Some might use the Chinese room argument to claim that the computer is not understanding anything, hence it’s only a rule-performing machine, and is hence not conscious. The point is however that the whole room understands it, even if the constituent parts don't. And that implies a cognitive process, and that is a conscious process. 

  
  

Something about the symbol grounding problem. Do objects in Frege’s system even need to exist? Yes.

  
  

One of the problems with the turing test is that it tests AI intelligence on human terms. It could be very intelligent, maybe even more intelligent than the smartest humans, and could still fail the Turing test. Not because it wants to (because it can deceive) but because intelligence is probably more than just human convention. 

  
  
  

An Artificial General Intelligence that performs roughly human standards of intelligence with conscious experience is what is necessary to complete the Turing test. Keep in mind that an AGI is not a hyperintelligence and wouldn’t necessarily fool the human into thinking it was dumber than it really was. 

  
  

Philosophical zombies. Input output. E.t.c.

If a human, with given inputs, react with a certain output. It is conceivable that a machine can be built to perform the same action, given the same input. 

  

  
  
  
  

When you turn language into statistics you can map the probabilities of various phrases. A meta mesmeriser will look over how to best match human language. 

  

AI deception, language as a tool for AGI to use to communicate with us puny humans.

  
  
  
  

Sources:

  

Cognition as Embodied Morphological Computation, Gordana Dodig-Crnkovic

  

Where Intelligence Lies: Externalist and Sociolinguistic Perspectives on the Turing Test and AI, Shlomo Danziger

  

Where Intelligence Lies: Externalist and Sociolinguistic Perspectives on the Turing Test and AI Shlomo Danziger

  
  

[https://en.wikipedia.org/wiki/Symbol_grounding_problem](https://en.wikipedia.org/wiki/Symbol_grounding_problem) 

  

[http://www.scu.edu.tw/philos/98class/Peng/05.pdf](http://www.scu.edu.tw/philos/98class/Peng/05.pdf) 

  

[https://arxiv.org/pdf/2004.05631.pdf](https://arxiv.org/pdf/2004.05631.pdf) 

  

Symbol grounding problem solved

[https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.78.3463&rep=rep1&type=pdf](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.78.3463&rep=rep1&type=pdf) 

  

[https://www.lesswrong.com/posts/ZDZmopKquzHYPRNxq/selection-vs-control](https://www.lesswrong.com/posts/ZDZmopKquzHYPRNxq/selection-vs-control) 

  

[https://www.lesswrong.com/posts/XWPJfgBymBbL3jdFd/an-58-mesa-optimization-what-it-is-and-why-we-should-care](https://www.lesswrong.com/posts/XWPJfgBymBbL3jdFd/an-58-mesa-optimization-what-it-is-and-why-we-should-care)**