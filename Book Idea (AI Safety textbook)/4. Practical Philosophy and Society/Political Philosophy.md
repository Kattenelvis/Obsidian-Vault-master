

- Societal changes
	- Post-Scarcity Economics
	- AI companions
- Futurology/Future studies
	- Prediction Markets
	- Memetics
		- Memetic viruses
		- Memetic hazards
- Decision making structures
	- Futarchy
	- Social choice theory
	- Jury's theorem
	- Digital Democracy
	- Liquid Democracy
		- Predictive liquid democracy
- Transhumanism
	- Life Extension
	- Merging with computers, mind upload, slow neuronal shift
	- Virtual Worlds, experience machines
	- Space colonization
	- Morphological freedom
	- Posthumanism
	- Different political interpretations of transhumanism
		- Anarcho-Transhumanism
		- Technocratic Transhumanism
		- Liberal Transhumanism
		- Xenofeminism
- Critiques of Transhumanism
	- Anti-Civ
	- Primitivism
	- Luddism
- Status quo-preservation is increasingly difficult over time, requiring extreme measures
- Apocalypses, maximizing or even barely satisficing values requires transhumanism to some extent.
- AI governance
	- Gone wrong: AI art, compensation and egalitarian distribution of resources
	- Frameworks for responsible AI governance
	- Pitfalls and lessons from past attempts at AI regulation 
	- International relations theory
	- Historical similarity: Nuclear stuff



We've mostly discussed AI generally abstracted away from human society at large. We've discussed various models of AI, their intrinsic properties, and questions of ethics regarding AI. But how do we ensure that ethical use of AI actually happens? How does AI fit into human society at large? How may society change, and how could a transhumanist or post-human future look like? 


# Societal Changes

We stand at the crossroads between various kinds of dystopian scenarios and utopian scenarios. The status quo will be very unlikely to be maintained, without extremely strict authoritarian measures. As such, we will have to expect and deal with rapid, irreversible change to human society with the advent of AGI and even narrow AI we've already developed. 


## Post Scarcity


One of the major potential societal changes that may occur with the advent of AGI, given medium or slow speed, 

## AI companions


# Decision making structures

How should we change (if we should change) our decision making structures for the construction of safe AGI? Well politically speaking, this may require navigating tough power structures that exists worldwide. 





# Futurology

As we saw in the [rationality] chapter, to take actions that satisfy our preferences, we need 


What will the future be like? Predicting the progress of AI and other things is hard, but it's not impossible to see some general statistical patterns.


![[Pasted image 20240322132140.png]]

## Forecasting the future

### Moore's Law





## Prediction markets

What is metaculus saying about AGI? Oh... Oh god!

A prediction market is a system where agents bet on certain outcomes will occur by some date. 

## Potential futures: Solarpunk
## Cyberpunk





# Game Theory and Capitalism: Is capitalism aligned with human values?

## Moloch, free riders and betrayal

Imagine a cafeteria. People are talking. However the loudness of the crowd make some people speak louder. This is not something people prefer, as it dries their throat and can be damaging to hearing in the long run. However as some people start speaking louder to overloud the crowd, the crowd consistently gets louder. The incentive of speaking louder has lead into a situation where everyone is speaking extremely loudly if not borderline shouting. We've just seen moloch - how local incentives can lead to a race to the bottom where no one wins.

Game theoretically it can be described as blah blah blah

Race towards dangerous AI between nation states/companies

Someone could come into the cafeteria and yell "EVERYONE LET'S TRY TO BE QUIET" that massively overlouds the crowd. This is an example of an agreement between nation states/companies to limit something dangerous. 


## Profit incentives and externalities as an alignment problem


Perhaps a similar problem to aligning AI with human values, is aligning the profit incentive with human values. Massive ideologies and movements, from communists to liberals to fascists, have different viewpoints as to what extent they are aligned, and how they should be aligned. A liberal may very well take it that the profit incentive aligns with human values - the reason people purchase items and companies generate profit is by satisfying human preferences after all. However most liberals, barring some more extreme libertarian strands of liberalism, will argue that externalities is an example of when the profit incentive is not aligned with human values, and propose regulations and penalties so as to change the profit incentive to continue being in alignment with human values.

[Neoclassical economic models here, say green economics or whatevs]  or even efficient market hypothesis, neoclassical welfare economics

However more left wing criticism aimed at the abovementioned system claims that the profit incentive will very often, if not almost essential to the profit incentive in more extreme cases, to not be aligned to human values. 

[Post-Keynesian models here]


It's worth noting that 
Me later: NOTING WHAT???

# The stages

## The high-technological human stage

## The transhuman stage

## The post human stage






# A transhumanist future?
[[6. Transhumanism, AGI, ASI, alignment]]




# Different political interpretations of transhumanism

The next section will explore different political views on transhumanism, and how they can be incorporated into existing political ideologies. While I'd argue that all of them are striving for the same, or atleast extremely similar values (given the size of the space of possible values) that their end goals are the same. As such, these are generally proposals on how to deal with the short and possibly medium term problems (or even long term assuming superintelligence is never invented) of human and the early stages of trans-human civilizations.   



## Liberal Transhumanism

Liberalism as an ideology generally involves a belief that human values and generally aligned with profit values, the social contract justifies statehood, human rights are valuable deontological commitments, liberal democracy is the most legitimate form of governance and negative freedoms (i.e freedom of speech, association, religion etc.) should be protected.

As it would likely take up a book, maybe even multiple books, to go over the nuances of liberalism, I cannot really afford myself to do that at this point. I will instead pursue how liberalism may aid or hinder AI safety, and its potential views on transhumanist policies discussed earlier.

Liberalism generally holds the deontological viewpoint of human rights, the idea that people have certain inalienable rights, no matter circumstances (except, as is often the case in liberal law systems, edgecases, where judges will have to decide and where the liberal system will contain more layers of checks and balances). These rights can be applied logically (in deontic logic) to figure the rightness of certain policies or actions. 

For instance, a liberal may argue that genetic engineering on humans may go against the right of bodily autonomy, and that only [epigenetic engineering] is permissible. 

Another example




## Anarcho-Transhumanism

Anarchism denies certain arguments which justifies the authority and legitimacy of liberal democracy, such as the social contract and the right for monopoly of violence. Anarchists are against unjust hierarchies [chomsky] and generally resist attempts at the establishment of hierarchy. 

Contrary to popular belief, anarchism is not about chaos, or just being chaotic in general (atleast not in the context of political philosophy). It's worth noting that anarchism generally supports certain kinds of structure, such as local democratic decision and delegation, collective ownership of industries, bottom-up decision making and decentralized economic planning.

An anarcho-transhumanist may criticize the idea of a singular ASI maximizing a single value function. They may instead argue that there should be many smaller agents, engaging in rational decision making on their own terms, without prisoners dilemmas or other power structures between them. 

A couple of reasons this may succeed in a post-human civilization is firstly that post-humans may be fully rational. This implies that they'd be able to engage in long term co-operative behavior, contractual agreement (with mathematical agreement), being fully honest with each other, having perfect information, and having specified utility functions and Bayesian belief system that doesn't subject them to any kind of money pump or Dutch book. This means they would enter agreements with each other, and arbitration can be done locally without any central authority. [source on that article with AGI's where they share utility functions]

Another good case for it is that on intergalactic scales, law will be difficult due to the limitations of the speed of light and the expansion of the universe. See more in [[Law]].

## Technocratic Transhumanism

Technocracy also denies certain arguments which justifies the  legitimacy of liberal democracy, most notably the notion that liberal democracy is the most legitimate governance.

Technocracy is about the rule of the technocrats, which are highly educated individuals, usually in STEM fields or the social sciences. The idea is that individuals with knowledge can also rule better, ignoring the Humean distinction between value propositions and fact propositions. 

The system is generally considered to be anti-democratic, in that it only allows the control of a small minority of individuals. 

But perhaps one dislikes dictatorial control but still doesn't believe liberal democracy is justified. In "Against democracy", argues for epistocracy, where people need a certain level of knowledge before being allowed to vote. 



## Soviet Transhumanism

	"I'm going to the ONE place that hasn't been corrupted by capitalism...SPACE"

*- Command whatever from that RTS game*



## Xenofeminism

The xenofeminist manifesto
## Life-Extension

But when we do live for a long time, will we get value lock-in from older generations? Or will regained life in older people lead to value drift? 

We can imagine a society where the boomer generation, being the largest, also keeps living on forever, even as new individuals are born (though likely at a lower rate, especially if mandated so by some government). This leads to some kind of partial value-lock in, as the values of the older generation gets stuck. New theories of physics, or philosophy, or new political movements, may not be able to gain any kind of ground among people with locked-in values for what is true. This is not to disparage older people and say that they can't change their values, they very likely can, but it's generally more difficult. Reasons may include a decrease in neuroplasticity as we age, and there are reasons to believe that future humans with anti-ageing technology will likely also have the ability to generate and regenerate brain tissue [source on trials of thsi already happening].

We can also imagine problems of overpopulation, leading to lowered standards of living, excessive resource consumption and accelerated global warming. Now it's worth noting that overpopulation itself it not enough for this, as only about 10% of the population is responsible for the majority of greenhouse gas emissions. However more people can hardly sustain combining higher standard of living with sustainable resource management. And anti-ageing may make this difficult, without programs to seriously curb children bearing.

Such systems may include a licence for having children, where for instance a parenting class may be necessary. We may also remove certain economic incentives for parenting, such as giving less welfare for every child that's born (So for instance, the welfare given would be say $400, then with two children $400+$300 and so on). Forceful sterilization may be used in extreme scenarios, though is to be generally avoided since it may affect the wrong person, may harm the person. If that is to be employed, however, always leave room for adoption given that some people, even if they are sterilized, may value having children. For more on how these policies can be discussed and voted on, see [Deliberative democracy].

## Genetic Engineering

Now what if we could edit genes and produce designer babies? This is crazy! Crazy cool that is. 

### Epigenetics

If one believes it is unethical to perform genetic engineering on human fetuses, one may perhaps instead take on epigenetics instead. This allows people to be modified after their born, allowing a greater degree of autonomy, but less potential impact of those edits. 









## Pause AI strategy


Some hierarchy is needed, accountability and have politicians deal with someone on the same level.

Alliances finding leaders we wanna get together and make alliance




# Morphological Freedom

One view is that people should have the freedom to change thier looks however they like. We have already been implementing this in society already, from tatoos to gender transitioning. However what if we take it one step further, and allowed people to change how they looked in much more radical ways?

In the game VRChat[source], people can change their avatar to almost any character that has been 3D modelled and implemented into a map for the user to pick up and be like that. What if something like this was plausible to do in rea llife? This would allow a whole lot of new opportunities for people to express themselves and their identity in unique and interesting ways. 

In the capabilities approach, they are value pluralist in the sense of resource distribution and capabilities of people. 
[The Capability Approach (Stanford Encyclopedia of Philosophy)](https://plato.stanford.edu/entries/capability-approach/)
The idea is that capabilities of people should be distributed aswell. We can do this with enhancements. Blind people will be able to see and so on (see chapter on philosophy of disability)

# Philosophy of Disability

While this is yet another section one could write a whole book on, this will deal with the potential ethical ramifications of transhumanist ideas in the context of disability philosophy.

Curing autism controversy

Curing blindness/deafness controversy

Isn't more abilities just better? Larger action space $A$. $|A^*|>|A|$. 



# Virtual Worlds and Experience Machines


Virtual worlds by David Chalmers


We might live in one already, look in simulation argument 


Nozick[source] postulated a thought experiment about a so called experience machine. As discussed in phenomenolgoy chapter, this means that any phenomenal space P is simulable. If such a machine were to exist, would you enter it?

Utilitarian views

Deontological views

Potential risks

Plausibility of it being constructed (yes it is plausible)

LITERALLY FAHRENHEIT 451!!!




# Fairness and Social Algorithms

The idea of Artificial Intelligence (AI) for Social Good (henceforth AI4SG) is becoming popular in many information societies and gaining traction within the AI community (Hager et al. 2017). Projects addressing AI4SG vary significantly. They range from models to predict septic shock (Henry et al. 2015) to game-theoretic models to prevent poaching (Fang et al. 2016); from online reinforcement learning to target HIV-education at homeless youths (Yadav, Chan, Jiang, et al. 2016) to probabilistic models to prevent harmful policing (Carton et al. 2016) and support student retention (Taddeo and Floridi 2018a). Indeed, new applications of AI4SG appear almost daily, making possible socially good outcomes that were once less easily achievable, unfeasible, or unaffordable.

