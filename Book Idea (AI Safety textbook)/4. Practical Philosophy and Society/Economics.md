[[Economics of AGI]]

The philosophy of economics of AI is big 



How do we optimize configurations of substance in the universe?

Whenever I eat a piece of chocolate, the nerve signals form a more optimized configuration given my preference relation (given that I preferer similar experience as before but with medium levels of hedonic pleasure). How do we optimize this to a large degree?

# The economics of the Singularity

https://arxiv.org/pdf/2403.12107
https://www.imf.org/en/Publications/fandd/issues/2023/12/Scenario-Planning-for-an-AGI-future-Anton-korinek
![[Korinek-chart1.jpg]]![[Korinek-chart2.jpg]]


But it seems unlikely that there'd be an unbounded distribution. Even if it is limited, as we've discussed earlier namely via the Lucas-Penrose arguments and the like is that no one is getting paid feeling intuitively whether a Gödel sentence is true or not.



# Universal basic income


"1. UBI is becoming a necessity for the survival of the economy

   Not, mind you, just to save people's lives. But without it the economy would collapse
   
   Specificly, without consumers there would be little drive for this.
   
   
   The economy would collapse for teh rich too. Unless they're okay with returning to a closed market with barely any market innovation
  
   I don't think UBI is the only solution, but it's a good conversation starter at least"


Nah you did a good job in giving an overview over what may happen without UBI in the future of complete workplace automation as every cognitive and physical ability of humans is simulatable. There may be other ways of ensuring that market collapse doesn't occur, for instance a post-money socialist computerized economy with distribution based on need/aggregated preferences. However, the urgency of the situation (especially given the advanced seen in just the last 2 years) may imply that UBI is our best shot at preventing a kind of disaster that may happen if traditional redistributive welfare systems are in place where a progressive income tax fund social welfare payouts when the unemployed has minimum living necessities that can no longer be paid for, all while fewer people pay income taxes. I doubt any kind of economy where human cognitive labour is automated would not have market innovation, given that automating innovation would be cheap and easy.






[Ben Goertzel - Wikipedia](https://en.wikipedia.org/wiki/Ben_Goertzel)

- Ben Goertzel (1992). _The Structure of Intelligence: A New Mathematical Model of Mind_. Springer.
- Ben Goertzel (1992). _The Evolving Mind_. Gordon and Breach.
- Ben Goertzel (1994). _Chaotic Logic: Language, Thought, and Reality from the Perspective of Complex Systems Science_. Plenum.
- Ben Goertzel and [Ted Goertzel](https://en.wikipedia.org/wiki/Ted_Goertzel "Ted Goertzel") (1996). _Linus Pauling: A Life in Science and Politics_. Basic.
- Ben Goertzel (2001). _Creating Internet Intelligence_. Springer.

- Ben Goertzel (2005). _Artificial General Intelligence_. Springer.
- Ben Goertzel (2006). _Probabilistic Logic Networks: A Comprehensive Framework for Uncertain Inference_. Plenum.
- Ben Goertzel (2006). _The Hidden Pattern: A Patternist Philosophy of Mind_. Brown Walker.
- Ben Goertzel (2007). _The Path to Posthumanity_. Academica.
- Ben Goertzel (2010). _A Cosmist Manifesto: Practical Philosophy for the Posthuman Age_. [Humanity+](https://en.wikipedia.org/wiki/Humanity%2B "Humanity+") Press.
- Ben Goertzel (2011). _Real-World Reasoning: Scalable Spatial Temporal and Causal Inference_. Atlantis Press.
- Ben Goertzel (2012). _Theoretical Foundations of Artificial General Intelligence_. Atlantis Press.
- Ben Goertzel (2014). _Engineering General Intelligence, Volumes 1 & 2_. Atlantis Press.
- Ben Goertzel (2014). _Between Ape and Artilect: Conversations with Pioneers of AGI and Other Transformative Technologies_. [Humanity+](https://en.wikipedia.org/wiki/Humanity%2B "Humanity+") Press.
- Ben Goertzel (2014). _Ten Years to the Singularity If We Really Really Try_. [Humanity+](https://en.wikipedia.org/wiki/Humanity%2B "Humanity+") Press.
- Ben Goertzel (2015). _The End of the Beginning: Life, Society and Economy on the Brink of the Singularity_. [Humanity+](https://en.wikipedia.org/wiki/Humanity%2B "Humanity+") Press.
- Ben Goertzel (2016). _AGI Revolution: An Inside View of the Rise of Artificial General Intelligence_. [Humanity+](https://en.wikipedia.org/wiki/Humanity%2B "Humanity+") Press.
- Ben Goertzel (2018). _The Evidence for Psi: Thirteen Empirical Research Reports_. McFarland.






As Goerzel 2010 writes, the post-singularity societies could have changes in some very unexpected areas. Many areas of human life is highly unoptimal for most humans, and can be improved by a superintelligence. 

For example, sexuality. One of Goertzels friends reports that he wants to remove his sexuality to better pursue transhumanist goals, despite what his wife thinks (although she could also in principle change her sexuality to be happier then, alternatively change husband afterwards). 

This really plays a role in a larger part of the aesthethic changes that we can imagine that a post-singularity society might come with. 

> "Art" may involve building baby universes or new AI systems or 9-dimensional meta-multiversal movies ... or scientific data-sets or theories or mathematical theorems ... or perfecting one's own array of mind-states ... or drawing pictures of trees on paper ... all of the above and many more! (Let infinity flowers bloom...!)



Another part of sub-optimality are emotional states of mind. The reason being that a rational decision $D$ such that action $D$ optimizes for some goal or general preference relation for $A$, and that $A$ knows that $D$ is more optimal in this regard, may for emotional reasons pick $E$, leading to suboptimal behaviour. 

This can be remedied by ensuring that, if we don't want go so far so as to abolish emotions, at the minimum atleast ensure that we can overrule our emotions in such a way so as to avoid sub-optimal outcomes. In the long run, this will likely lead to more friendly, less warfare focused civilization. The way we might be able to have some reason to believe this is because of game-theoretic reasons. In an iterated prisoners dilemma, it is rational to perform tit-for-tat with forgiveness as an strategy. We might never engage with forgiveness as a strategy if we feel broken, so we may aswell pick to keep being mean to our opponent. However this is a bad strategy in the long run, especially if the opponent is able to show willingness to cooperate. 


Idea: Instead of calling is "post-singularity", given that it might be gradual rather than a singularity point, perhaps something like the "post-human society". Don't just call it this, discuss this in a section on this topic and definitions. 



Before the singularity

The ever increasing presence of humanoid robots demonstrates that eventually, most industries could in principle be automatable and no longer be in any need of human labour. 

A reasonable approximation. We might be able to approximate the number of robots needed to be manufactured and such feasibility to be able to replace all industry in the world.

Assume total labour hours in mining, manufacturing, healthcare, agriculture is $L$. 

Since a robot can work 24/7, with exception of maintenance, we can assume that a single robot can replace roughly 4-5 human workers assuming they are equally efficient. Let's call that value $K$. We then get that $L/K$. 

In Marx capital there's a replacement wage for each human for upkeep. This can be drastically lower in robots, perhaps only being energy. And as renewable sources of energy keep getting cheaper, one plausible future is cheap abundant renewable energy. We can thus approximate these costs as very low.

If we also get rid of "bullshit jobs" [source to book], such as middle management, which are already useless, but can be made utterly redundant by the rise of robots, we can see even fewer people needing work. PR as a whole can be abolished. 

What we're left with are hyper-productive AI robots in fully or almost fully automated factories. So after all, we can expect perhaps 1 robot can in the long run replace 7-10 human workers. If we assume $K=10$, we can then take the current number of employed people in industrialized countries (typically around a third to half the population) and seeing we only need a tenth of that to work. Hence, in Sweden, where I'm from, we could do with roughly 500,000 robots. Assuming building a robot is as resource intensive as building automobiles, this isn't entirely unreasonable to be achievable with light scaling. 

The general formula would be something like. With the fraction of the population as workers as $W$, $P$ as total population, then for any nation we get $WP/K$ as the number of robots needed for full automation. So for sweden, that is $0.5\times 10 000 000 / 10 = 500000$




One worry with full automation and AGI (artificial general intelligence) is wondering who will be left when no one can buy the products being offered by fully automated companies?
