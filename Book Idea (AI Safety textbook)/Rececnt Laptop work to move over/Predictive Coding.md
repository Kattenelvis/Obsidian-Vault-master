

[Connectionism Predictive Coding (Stanford Encyclopedia of Philosophy)](https://plato.stanford.edu/entries/connectionism/#PC)


Top-Down encodings: General features of say, an image or moving frame, are predicted

Bottom-Up encoding: Small features will feed up into inferences for the general features.

Error minimization: The differences between general features and small features will be minimized. 

**Principle \<num\>**:  Predictive coding consists of top-down encodings, bottom-up encodings, and minimizing the errors between the encodings.


Edge finding is related to convolutional neural networks and edge-finding


Vision in general. As argued by Hoffman 1998 and other papers, the agent constructs the world rather than being fed the world directly. That is to say, 2D visual input is processed by various cognitive modules in the visual cortex and other regions, generating a 3D representation. However, a 3D representation is underdetermined by the 2D visual input (as can be explicitly seen in some illusions). This spatial representation procedure allows for good stuff.

To formalize it, consider a 2D input matrix $M$. Each member of $M$ is a set of pixel color values in visual space. As it is processed by a 3D interpreter $D$, we get that $D(M)$ as a matrix which includes a depth value to each region. Perhaps also while encoding spatial structure in general.

As some studies with rat brains shows, aswell as that book on mental content, there's a structural correspondence between the external content of thought and the structure via an isomorphism. There might be problem with this in conjunction with the skepticism postulate but nevertheless valuable. 

Visual processing takes up 20-30% of the activity of the brain,
Idea: Are blind people less intelligent? Born blind vs becoming blind? I assume those becoming blind remain intelligent while those born blind are less intelligent on average. 

> On the other hand, PC models do appear more neurally plausible than backpropagation architectures, for there is no need for a separate process of training on an externally provided set of training samples. Instead, predictions replace the role of the training set, so that learning and interacting with the environment are two sides of a unified unsupervised process.


> Predictive coding has interesting implications for themes in the philosophy of cognitive science. By integrating the processes of top-down prediction with bottom-up error detection, the PC account of perception views it as intrinsically theory-laden. Deployment of the conceptual categorization of the world embodied in higher levels of the net is essential to the very process of gathering data about the world. This underscores, as well, tight linkages between belief, imaginative abilities, and perception (Grush 2004).


> The PC paradigm also tends to support situated or embodied conceptions of cognition, for it views action as a dynamic interaction between the organismâ€™s effects on the environment, its predictions concerning those effects (its plans), and its continual monitoring of error, which provides feedback to help ensure success.


We might expect an agent $A$ of which minimizes prediction error to always be sitting in a dark empty room. We expect agents to be slightly more multi-faceted in its goal structure or preference relation other than minimization of prediction error.

