

[Ben Goertzel - Wikipedia](https://en.wikipedia.org/wiki/Ben_Goertzel)

- Ben Goertzel (1992). _The Structure of Intelligence: A New Mathematical Model of Mind_. Springer.
- Ben Goertzel (1992). _The Evolving Mind_. Gordon and Breach.
- Ben Goertzel (1994). _Chaotic Logic: Language, Thought, and Reality from the Perspective of Complex Systems Science_. Plenum.
- Ben Goertzel and [Ted Goertzel](https://en.wikipedia.org/wiki/Ted_Goertzel "Ted Goertzel") (1996). _Linus Pauling: A Life in Science and Politics_. Basic.
- Ben Goertzel (2001). _Creating Internet Intelligence_. Springer.

- Ben Goertzel (2005). _Artificial General Intelligence_. Springer.
- Ben Goertzel (2006). _Probabilistic Logic Networks: A Comprehensive Framework for Uncertain Inference_. Plenum.
- Ben Goertzel (2006). _The Hidden Pattern: A Patternist Philosophy of Mind_. Brown Walker.
- Ben Goertzel (2007). _The Path to Posthumanity_. Academica.
- Ben Goertzel (2010). _A Cosmist Manifesto: Practical Philosophy for the Posthuman Age_. [Humanity+](https://en.wikipedia.org/wiki/Humanity%2B "Humanity+") Press.
- Ben Goertzel (2011). _Real-World Reasoning: Scalable Spatial Temporal and Causal Inference_. Atlantis Press.
- Ben Goertzel (2012). _Theoretical Foundations of Artificial General Intelligence_. Atlantis Press.
- Ben Goertzel (2014). _Engineering General Intelligence, Volumes 1 & 2_. Atlantis Press.
- Ben Goertzel (2014). _Between Ape and Artilect: Conversations with Pioneers of AGI and Other Transformative Technologies_. [Humanity+](https://en.wikipedia.org/wiki/Humanity%2B "Humanity+") Press.
- Ben Goertzel (2014). _Ten Years to the Singularity If We Really Really Try_. [Humanity+](https://en.wikipedia.org/wiki/Humanity%2B "Humanity+") Press.
- Ben Goertzel (2015). _The End of the Beginning: Life, Society and Economy on the Brink of the Singularity_. [Humanity+](https://en.wikipedia.org/wiki/Humanity%2B "Humanity+") Press.
- Ben Goertzel (2016). _AGI Revolution: An Inside View of the Rise of Artificial General Intelligence_. [Humanity+](https://en.wikipedia.org/wiki/Humanity%2B "Humanity+") Press.
- Ben Goertzel (2018). _The Evidence for Psi: Thirteen Empirical Research Reports_. McFarland.






As Goerzel 2010 writes, the post-singularity societies could have changes in some very unexpected areas. Many areas of human life is highly unoptimal for most humans, and can be improved by a superintelligence. 

For example, sexuality. One of Goertzels friends reports that he wants to remove his sexuality to better pursue transhumanist goals, despite what his wife thinks (although she could also in principle change her sexuality to be happier then, or change husband). 

However, it's important to note that for some people, one's sexuality can be an important to someone's self-image and constructed self. The idea that a post-human societies should get rid of all interesting expressions of sexuality and interesting scenarios involving kinks and fetishes is I think if not wrong, atleast aesthetically non-pleasing for me. I think he was limited by his own ability to imagine interesting sexual scenarios involving sci-fi, fantasy and other concepts, given his likely mostly kink-free heterosexuality. 


This really plays a role in a larger part of the aesthethic changes that we can imagine that a post-singularity society might come with. 

> "Art" may involve building baby universes or new AI systems or 9-dimensional meta-multiversal movies ... or scientific data-sets or theories or mathematical theorems ... or perfecting one's own array of mind-states ... or drawing pictures of trees on paper ... all of the above and many more! (Let infinity flowers bloom...!)



Another part of sub-optimality are emotional states of mind. The reason being that a rational decision $D$ such that action $D$ optimizes for some goal or general preference relation for $A$, and that $A$ knows that $D$ is more optimal in this regard, may for emotional reasons pick $E$, leading to suboptimal behaviour. 

This can be remedied by ensuring that, if we don't want go so far so as to abolish emotions, at the minimum atleast ensure that we can overrule our emotions in such a way so as to avoid sub-optimal outcomes. In the long run, this will likely lead to more friendly, less warfare focused civilization. The way we might be able to have some reason to believe this is because of game-theoretic reasons. In an iterated prisoners dilemma, it is rational to perform tit-for-tat with forgiveness as an strategy. We might never engage with forgiveness as a strategy if we feel broken, so we may aswell pick to keep being mean to our opponent. However this is a bad strategy in the long run, especially if the opponent is able to show willingness to cooperate. 


Idea: Instead of calling is "post-singularity", given that it might be gradual rather than a singularity point, perhaps something like the "post-human society". Don't just call it this, discuss this in a section on this topic and definitions. 













Before the singularity

The ever increasing presence of humanoid robots demonstrates that eventually, most industries could in principle be automatable and no longer be in any need of human labour. 

A reasonable approximation. We might be able to approximate the number of robots needed to be manufactured and such feasibility to be able to replace all industry in the world.

Assume total labour hours in mining, manufacturing, healthcare, agriculture is $L$. 

Since a robot can work 24/7, with exception of maintenance, we can assume that a single robot can replace roughly 4-5 human workers assuming they are equally efficient. Let's call that value $K$. We then get that $L/K$. 

In Marx capital there's a replacement wage for each human for upkeep. This can be drastically lower in robots, perhaps only being energy. And as renewable sources of energy keep getting cheaper, one plausible future is cheap abundant renewable energy. We can thus approximate these costs as very low.

If we also get rid of "bullshit jobs" [source to book], such as middle management, which are already useless, but can be made utterly redundant by the rise of robots, we can see even fewer people needing work. PR as a whole can be abolished. 

What we're left with are hyper-productive AI robots in fully or almost fully automated factories. So after all, we can expect perhaps 1 robot can in the long run replace 7-10 human workers. If we assume $K=10$, we can then take the current number of employed people in industrialized countries (typically around a third to half the population) and seeing we only need a tenth of that to work. Hence, in Sweden, where I'm from, we could do with roughly 500,000 robots. Assuming building a robot is as resource intensive as building automobiles, this isn't entirely unreasonable to be achievable with light scaling. 

The general formula would be something like. With the fraction of the population as workers as $W$, $P$ as total population, then for any nation we get $WP/K$ as the number of robots needed for full automation. So for sweden, that is $0.5\times 10 000 000 / 10 = 500000$




One worry with full automation and AGI (artificial general intelligence) is wondering who will be left when no one can buy the products being offered by fully automated companies?

Here's a potential scenario on how the owner class could manage to survive, without implementing universal basic income. Say that full automation is possible. This automation progress leads to a complete layoff for everyone in the working class. This would perhaps, include middle-managers, the board and even CEO's of companies. The owner class, the one's who own the companies, could allow the robots to produce all the goods they need to survive. No one has to buy their goods, they establish what is essentially a planned communist commune bubble for themselves. Everyone's needs will be met through a planned robot economy. Meanwhile the rest of humans leads a life into poverty and famine, eventually dying out. The fact that a revolution could occur is potentially squashed with an automated police force. There's no necessary need to hire humans, who could join the protesters side, to be police or military, when those jobs could also, by the assumptions given above, be fully automated. 

Such a scenario is terrifying for everyone not part of the owner class. The owner class could in principle be able to indefinitely hold of a revolution while gathering all the resources themselves without need for the rest. 

By the time of writing this, the situation does not seem to be good on a global scale. With Trump as the winner of the US election, probably the worst election results since selecting Bush over Gore, we might soon face a world in which wealthy oligarchs seize power fully in the united states, at the same time as AGI gets developed in that same country. Chinese state owned corporations, beholden by the communist party of China, under similar incentives, will be beholden to a small elite of party elites, and AGI could very well be developed there. The only part of the world I would trust with AGI being developed would be the European Union, which I think does a generally good work at keeping the corporations at bay (not too much to threaten the owner-worker class system in place, but nevertheless minimizes the suffering that system brings). However, AGI and tech in general has been slow in the EU. There doesn't seem like AGI is on the table. It could be because of just those regulations which minimize the damage done by the owner class that the places where that damage runs rampant like the US and China are the places developing AI. 

It's worth noting that I don't think that greed is the main motivator. Let greed be defined as a personally trait of accumulation of liquid assets and investments. To a large extent, that accumulation of liquid assets and investments is a product of the way the current financial system goes, for people's own survival, rather than a personality trait on its own. 

Investors and Sharehold owners, for instance, Blackrock, may demand that companies, especially those in the S&P 500, keep making money. They hold voting power in the corporations. They decide to take actions which optimize shareholder value. They do this to keep customers and not go bankrupt. Stagnant profits is not enough, it has to grow to ensure growing stock portfolio values. Perhaps if dividend stocks end up being the only stocks available, this could be prevented. Regardless, ever increasing dividends might still be demanded. The accumulation of surplus capital eventually yields negative outcomes to members of the working class. 

This is all intertwined with the banking system. Loans are granted by the expectation of paying it back with interest, an ever increasing profit incentive. Companies keep taking loans to establish ever newer ventures in expectation of received growth. 

It's also interlinked with globalism, globalist capitalism and neo-colonialism. The establishment of new markets across the world is important for the growth and accumulation of capital and increasing profits. Generally speaking, wealth is extracted from peripheral nations into the imperial and semi-imperial core. The multinational corporations benefit while most people in the peripheral nations suffer. The middle class is bolstered and can recieve cheaper goods from cheap labour in the periphery. If those nations grow a sizable middle class, this could strain the owner class of cheap labour. Of course, under full automation, this entire system is thrown out the window. Now no one is exploited, but everyone except the owner class are starving. 

That wealthy individuals decide to dress fancy, and other displays of wealth, is often another strategy to uphold this system. I doubt they are genuinely happy or desire many of the things they buy. Salary increase after $100000 per year barely yields more happiness. The wealthy class are buying Rolex watches, Lamborghini cars, McMansions and private jets. A lot of it is to signal wealth to investors and others. They are not happier with it. They pursue it for self-preservation reasons and systematic pressures. But without the self-preservation reasons, we can expect them to furfil their biggest wishes with the rise of AGI that the average human will be withheld from. 

My call to the world is that we have to be optimistic and fight for a better future. With the right policies, we might not even require that major of a change in the way that we do things to pave the path for a radical change post-AGI. 

Here's what I propose:

1. Work-Abolitionism should be high on the agenda. It is good that jobs are going away. Politicians need to stop pandering to "it create jobs" mentality. At this point, we should celebrate the elimination of work.
   
2. Establish Universal Basic Income. Not just a fixed value, but one that grows with inflation and more. It is a no-questions asked proposal, everyone within the nation, perhaps atleast those who live there, should receive it. The European Union should establish UBI on a continental scale. 
   
3. For a more radical approach, start letting people have larger impact and voting rights in companies. More state-corporate partnerships and ownership, more democratic oversight. Allow for the eventual takeover of companies away from the owner class once AGI has been reached. One example of this is what the Swedish social democratic party tried to establish in the 80s (and was removed a couple years later) which was a fund for the workers unions to purchase the stocks of the company, with the goal of majority ownership by the workers unions in corporations. This will allow for a worker class optimization of value rather than one for a small number of financiers in the owner class. 
   
4. Prepare society for ASI (artificial superintelligence). That AGI could become ASI might happen in a few hours via a technological singularity, or a decade, we just don't know. Whenever AGI hits, prepare for ASI. Prepare for a societal shift greater than anything we've seen so far.
   
5. Believe that change is possible. We might live in a society of capitalist realism, where we think this system is all there can be, and have a hard time conceptualizing non-capitalist structures of power. What we need to do is break out of that, and establish a positive utopian vision for a post-AGI world, such as in my [blog post] on allowing dyson sphere's and mind upload into virtual worlds of our wildest dreams and imaginations can be established for billions (or much much much more) number of years. The Solarpunk aesthethic is interesting and I love it, it is certiantly better than what we have now. But I find that it is ultimately underwhelming to what I think our potential as a species really could be. Our cosmic endowment is to colonize the stars and shape it in our way.
   
6. Forbid usage of AI systems in the military, including for defence. Forbid AI control on nuclear capabilities. Forbid AI usage in engineering viruses. Forbid AI from developing chemical weaponry. Limit AI usage on stock markets. Ban usage of police robots. 

7. Work and fight for it. We have to get it into the heads of the politicians that we want this. If something more than a friendly protest is required, we should do it. We cannot entirely rely on the owner-class not waging war against the working-class for their own self-preservation against the self-preservation for the working class. We have to establish networks of support and political campaigning. 