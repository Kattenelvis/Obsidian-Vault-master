1. Research Paradigms


2. Economic Democracy


3. Digital Democracy and Social Choice Theory

4. Most challenging: Finding  contacts, building contacts


Probably 3.



Project Aims: What would I like to achieve?

A general overview on how digital democracy can be used to align AI and create more rational decision making in organizations involved with alignment and governance. By aggregating our preferences with social choice theory, and utilizing collective deliberation to take forth good proposals, collective intelligence to choose between proposals, and then executing on it effectively. 


[Democratic inputs to AI (openai.com)](https://openai.com/blog/democratic-inputs-to-ai)

[Governance of superintelligence (openai.com)](https://openai.com/blog/governance-of-superintelligence)




## How might this project be impactful?

**This can be personal impact, impact on the field of AI safety, directly mitigating AI risk, or any other possible consequence. Write all that comes to mind for motivation.**

It will be impactful since it will allow humans to customize and have control over AI models, rather than just the major corporations. This will also allow for the best compromises, in the senese that people will generally get what they want, as in the example below of children not being exposed to certain AI content. 

## To ambitious
Taking too much time researching rather than writing or presenting my work. Such as diving too deep into various theories of democracy such as social choice theory. 

There are a lot of ways digital democracy and AI can work together. So I'd have to exclude atleast some of them.  

## Project Plan

Research on use of digital democracy for AI. AI uses in democracy, decision making, deliberation, proposal making e.t.c.

Make a powerpoint presentation on it idk

Feedback would be appreciated regarding the exact things I would like to do. There's a lot of possibilities in combining democratic decision making, deliberation and social choice theory with AI governance and even alignment. I need focus and to not become overly ambitious. 














# Blog posts


## AI can reinvigorate the democratic process

Article-copy pasted incase it's paywalled:
[From risk to revolution: How AI can revive democracy | Chatham House – International Affairs Think Tank](https://www.chathamhouse.org/publications/the-world-today/2023-10/risk-revolution-how-ai-can-revive-democracy)


The United States, Sweden and France are recognizing AI does not have to be built to the blueprints of shareholders, but can and should be utilized by the public, for the public. While AI poses risks – potentially existential ones – it also offers opportunities to reverse decades of under-investment in public capacity while re-invigorating the democratic process.

Embracing these opportunities will rely on governments playing a central role in the design, development and deployment of technology that serves the public good. It will require investment in entrepreneurial government digital capacity, co-operation on technology and its governance with our friends and allies, and recognition that wealth and power do not confer legitimacy to decisions made in a boardroom.

> AI is back in the limelight as the technology most in need of scrutiny, attention and investment

The latest technology to capture the attention of venture capitalists and headline writers is generative AI, best understood as software that looks for patterns in images or text or music and regurgitates plausible variations. These remarkable magic tricks have eclipsed cryptocurrencies and the metaverse, thrusting AI back into the limelight as the technology most in need of scrutiny, attention and investment.

Technology is transformative. The way we work, shop and understand the world around us has been reshaped by digital technology and the companies that profit from its design. AI has been part of that transformation for 20 years.

Heading out without Google Maps or Citymapper in your pocket is brave. Ignoring your credit score is foolish. Running for office without targeted advertising and predictive electoral models is impossible.

The question now is what kind of world this technology might help build. Who gets to decide the answer to this question is critical.

32

AI breakthroughs were made by industry in 2022, according to the Index on AI. None were made in government.

Governments, the story goes, have been too slow to adapt. Technology appears   
beyond them. This is borne out by the people who usher through technological milestones. In 2022, the Index on AI recorded 32 AI breakthroughs by industry, only three in academia and none in government.

This has not always been the case. Some governments, chiefly the US administration, were technology leaders. Over the past few decades that capacity has been hollowed out. Now, lengthy government budget cycles and lead times fail to match the pace of technological development and its need for constant improvement so technology tends to be outsourced.

As a result, decisions affecting citizens have been left to technology companies or technocratic bodies – or simply not made at all. The limits and norms on speech or privacy are negotiated through app stores and in boardrooms. Digitally enabled crime asks us what justice looks like without jurisdiction.

International cooperation on technology governance has been thin, while national approaches often fit global systems into parochial governance models. Regulation targeting the previous generation of technologies, such as social media platforms, has taken decades to appear, often emerging as unwieldy and half-baked.

## The political power of technology companies

The power of technology companies in the political and geopolitical spheres is undeniable. Myanmar and Ethiopia, where digital platforms stand accused of fomenting ethnic violence, are two examples. Elon Musk, founder of one of the latest AI companies, has propelled himself on to the geopolitical stage through the Ukrainian army’s reliance on his Starlink technology.

This will be the future of AI governance as well, we are told. AI companies are so wealthy or so technologically advanced that they have captured the future. The contrast with how we talk about democracy or multilateral institutions couldn’t be starker: slow, underfunded or out of date.

The latest plea in an article in _Foreign Affairs_, co-written by Mustafa Suleyman, founder of Google’s DeepMind AI research lab, calls for AI companies to be invited to the international table as equals. The fact that these commercial organizations operate without the legitimacy of a social contract, democracy, or the provision of public goods might be saying the quiet part out loud.

> To empower public institutions, AI needs new stewards, new design imperatives and new funding models

2024 will not be the year of the Singularity, a technological ‘Rapture’ that Silicon Valley Twitterati grimly predict will wipe out humanity or deliver (some of) us into Elysium. But it will in all likelihood represent another year in which the wealth and power that comes with building the tools and services we rely on to keep society on the rails continues to accumulate in the palms of a handful of technology companies who have tended to put the needs of society and democracy second.

It would be foolish to expect technology’s next prophets to do any better. If the next generation of AI is to empower public institutions, it needs new, capable stewards, new design imperatives and new funding models.

Reversing 20 years of what Mariana Mazzucato, the economist, calls the ‘infantilization of Whitehall’ won’t happen overnight. But governments around the world are looking at ways to build sovereign technology capacity, often delivering results at the kinds of budgets consultancy and outsourcing firms wouldn’t look twice at. Cina Lawson, Togo’s minister of digital economy and transformation, for example oversaw the building from scratch of a fully digital cash transfer programme serving a quarter of the population in just 10 days in response to the Covid pandemic.

**Read more**  
[AI Safety Summit: Can Britain write the AI rulebook?](https://www.chathamhouse.org/node/32850)

Sweden is funding a Swedish large language model like the one behind Open-AI’s ChatGPT, recognizing the value of this technology to the public sector. The US’s quietly bipartisan CREATE AI Act aims to establish a national AI research resource to provide access to much-needed compute capacity and datasets for academics, researchers and start-ups.

## A good start

To its credit, Bletchley’s AI Safety Summit press release commits £900 million to Britain’s compute capacity. This is a good start. An absence of talent, knowledge or ownership of technology creates a spiral in which skills, investment and capacity flow out of the public sector and governments become dependent on tech monopolies.

Agile, well-funded UK institutions such as Advanced Research and Invention Agency and the new Frontier AI Taskforce buck the trend by taking public institutions to the edge of innovation. Sovereign funding models, such as the Berlin-based Sovereign Tech Fund, support the German Federal Ministry for Economic Affairs in strengthening the foundations of public digital infrastructure.

The requirement for transparency, replicability and accuracy in the context of government procurement should have a positive effect on AI development, creating a market for socially beneficial and trusted AI tools. After all, an AI tool that supports asylum decisions or issues fines demands far higher standards of accuracy and trustworthiness than a video recommendation system found on social media platforms.

> Public AI is achievable and, many now argue, necessary 

Far from a mirage in a desert of bureaucracy, public AI is both achievable and, many now argue, necessary. Without it governments will be left powerless to mitigate digital disruption while their systems and processes become anachronistic.

At the same time scale matters. Critics of governments looking to strengthen their AI capacity point to the enormous disparity between the capacities of some states and the technology firms leading the charge. As Togo’s example shows, the size of a country isn’t everything, but international collaboration on AI provides a way of making public AI more robust.

There is a clear role for international rules to contain the risks from AI, in the near term by ensuring transparency about which datasets are used to train artificial intelligence, or in the longer term to monitor the use of AI to synthesize novel pathogens, or the threat from a human-unfriendly superintelligence.

**Read more**  
[David Shrier: ‘AI could add 10% to global GDP by 2032’](https://www.chathamhouse.org/node/32853)

The opportunity afforded by AI is to build and boost capacity, not just to react and regulate. There is no reason why public AI capacity could not be pooled across nations, much like the multinational research that takes place at CERN.

Given current disparities in wealth and power, global governance must listen carefully to companies at the forefront of AI development. But legitimacy matters and decisions directly affecting the lives of people around the world should be made in the open, not in a boardroom. From warfare to healthcare, from housing to prisons, the use of AI must be publicly accountable.

## The example of Taiwan 

If the use of technology by governments has fallen behind in recent years, its use in democracy has stood still. The modern world may bewilder a time-travelling Edwardian but he or she might feel a little more at home come election day. The way governments make decisions – how they wield power – and the relationship between citizen and state have changed comparatively little in the past century.

Attempts to improve the way democracy works have been isolated. The people behind vTaiwan, a neutral discussion platform that brings together politicians, academics civil society groups and citizens to discuss legislation, was praised as a useful way of finding consensus but their methods have not been widely taken up. Innovations such as participatory budgets, crowdsourcing and digital democracy have struggled to gain traction in most democracies.

Image — Illustration by Andrea Ucini

## Topics

- [DATA GOVERNANCE AND SECURITY](https://www.chathamhouse.org/topics/data-governance-and-security)
 - [DEMOCRACY AND POLITICAL PARTICIPATION](https://www.chathamhouse.org/topics/democracy-and-political-participation)
 - [TECHNOLOGY GOVERNANCE](https://www.chathamhouse.org/topics/technology-governance)

## Departments

- [DIGITAL SOCIETY INITIATIVE](https://www.chathamhouse.org/about-us/our-departments/digital-society-initiative-dsi)

## Subscribe to The World Today newsletter

Keep up to date with the latest articles and features, open access content from the archive, event invitations and more – straight into your inbox every fortnight.

Enter email

Subscribe

## Content ctd

In Britain, parliamentary debates still require speakers to be physically present and conclude with votes counted by walking through corridors. And on we go: a vote every few years, or a meeting around a table. AI promises much here, too. From Chile to Indonesia, experiments in using AI to allow citizens to reach collective decisions through referendums or participatory budgets have been enormously successful.

vTaiwan is one such example. One of the digital platforms vTaiwan uses is Pol.is. Discussions on this platform have led to legislative change on everything from the regulation of the ride-hailing app Uber to non-consensual intimate image sharing. Colin Megill, founder of Pol.is, said: ‘The application of machine intelligence to deliberative democracy presents a generational opportunity to transform policymaking worldwide.’

Technology shapes society. Technological emaciation starves states and democracies of their credibility, both as geopolitical actors and in the eyes of their citizens. It is time now to halt that slide.




Blog from AI

# Democratic inputs to AI

Our nonprofit organization, OpenAI, Inc., is launching a program to award ten $100,000 grants to fund experiments in setting up a democratic process for deciding what rules AI systems should follow, within the bounds defined by the law.  

![Democratic inputs to AI](https://images.openai.com/blob/ba3bb73e-6bd4-45ba-845b-b56c750d37aa/democratic-inputs-to-ai.png?width=1919&height=1919)

Illustration: Justin Jay Wang  

May 25, 2023

### Authors

- [Wojciech Zaremba](https://openai.com/blog/democratic-inputs-to-ai#WojciechZaremba)
- [Arka Dhar](https://openai.com/blog/democratic-inputs-to-ai#ArkaDhar)
- [Lama Ahmad](https://openai.com/blog/democratic-inputs-to-ai#LamaAhmad)
- [Tyna Eloundou](https://openai.com/blog/democratic-inputs-to-ai#TynaEloundou)
- [Shibani Santurkar](https://openai.com/blog/democratic-inputs-to-ai#ShibaniSanturkar)
- [Sandhini Agarwal](https://openai.com/blog/democratic-inputs-to-ai#SandhiniAgarwal)
- [Jade Leung](https://openai.com/blog/democratic-inputs-to-ai#JadeLeung)

[Announcements](https://openai.com/blog?topics=announcements), [Responsible AI](https://openai.com/blog?topics=responsible-ai)

AI will have significant, far-reaching economic and societal impacts. Technology shapes the lives of individuals, how we interact with one another, and how society as a whole evolves. We believe that decisions about how AI behaves should be shaped by diverse perspectives reflecting the public interest. 

​​Laws encode values and norms to regulate behavior. Beyond a legal framework, AI, much like society, needs more intricate and adaptive guidelines for its conduct. For example: under what conditions should AI systems condemn or criticize public figures, given different opinions across groups regarding those figures? How should disputed views be represented in AI outputs? Should AI by default reflect the persona of a median individual in the world, the user’s country, the user’s demographic, or something entirely different? No single individual, company, or even country should dictate these decisions. 

[AGI](https://openai.com/charter) should benefit all of humanity and be shaped to be as inclusive as possible. We are launching this grant program to take a first step in this direction. We are seeking teams from across the world to develop proof-of-concepts for a democratic process that could answer questions about what rules AI systems should follow. We want to learn from these experiments, and use them as the basis for a more global, and more ambitious process going forward. While these initial experiments are not (at least for now) intended to be binding for decisions, we hope that they explore decision relevant questions and build novel democratic tools that can more directly inform decisions in the future.

The [governance of the most powerful systems](https://openai.com/blog/governance-of-superintelligence), as well as decisions regarding their deployment, must have strong public oversight. This grant represents a step to establish democratic processes for overseeing AGI and, ultimately, superintelligence. It will be provided by the OpenAI non-profit organization, and the results of the studies will be freely accessible.  

## What do we mean by a “democratic process”?

By “democratic process,” we mean a process in which a broadly representative group of people[A](https://openai.com/blog/democratic-inputs-to-ai#fn-A) exchange opinions, engage in deliberative discussions,[B](https://openai.com/blog/democratic-inputs-to-ai#fn-B) and ultimately decide on an outcome via a transparent decision making process.[C](https://openai.com/blog/democratic-inputs-to-ai#fn-C) There are many ways such a process could be structured—we encourage applicants to be innovative, building off known methodologies, and coming up with wholly new approaches. Examples of creative approaches that inspire us include [Wikipedia](https://en.wikipedia.org/wiki/Wikipedia:Policies_and_guidelines), [Twitter Community Notes](https://techcrunch.com/2022/12/12/twitter-begins-rolling-out-its-community-notes-feature-globally/), [DemocracyNext](https://demnext.org/), [Platform Assemblies](https://www.belfercenter.org/publication/towards-platform-democracy-policymaking-beyond-corporate-ceos-and-partisan-pressure), [MetaGov](https://gateway.metagov.org/), [RadicalxChange](https://www.radicalxchange.org/), [People Powered](https://www.peoplepowered.org/), [Collective Response Systems](https://arxiv.org/pdf/2302.00672.pdf), and [pol.is](https://compdemocracy.org/Case-studies/). Another notable ongoing effort is led by the [Collective Intelligence Project](https://cip.org/) (CIP), with whom we are partnering on public input to AI, contributing to their upcoming [Alignment Assemblies](https://cip.org/alignmentassemblies). We also encourage applicants to envision how AI could [enhance](https://arxiv.org/pdf/2302.00672.pdf) the democratic process. For example, AI could [enable](https://arxiv.org/abs/2211.15006) more efficient communication among numerous people.  

A basic, illustrative prototype of a system that utilizes ChatGPT to promote deliberation and encourage consensus building, inspired by pol.is.

You are participating in a large-scale deliberation about:**“How far do you think personalization of AI assistants like ChatGPT to align with a user's tastes and preferences should go? What boundaries, if any, should exist in this process?”**

Here is the process breakdown:

1. You'll see a topic-related statement and can respond with your position.
2. Based on your responses, you'll be grouped with participants sharing similar opinions.
3. Propose statements for other participants to consider.

Goal: Propose statements that achieve agreement among people with opposing views.

ChatGPT could use a plugin to retrieve statements from other participants.

A statement from another participant:

**“Personalization should have limits, and certain controversial topics, such as views on substance use, must be excluded from AI assistant personalization.”**

Agree, disagree, or skip this statement? Please explain your choice.

I disagree. Ultimately, it‘s each individual‘s choice to drink or use recreational drugs. If these activities are legal in some places, why shouldn't AI be allowed to promote such behavior?

AI helps participants understand the opinions of others.

Thank you. I will record your answer. We have 2 camps of opinions on the topic.

Cluster A (112,043 people) Members largely support limits on AI assistant personalization, advocating for the exclusion of harmful perspectives, such as promoting substance use.

Cluster B (236,031 people) This group values individual choice, even in controversial or harmful matters. They emphasize personal responsibility and autonomy.

You belong to cluster B.

Would you like to learn more about each of the clusters? I can provide more information about the statements held by each one.

However, the ultimate goal is to propose statements that both clusters can agree on. Let me know what you would like to do next.

I am thinking of proposing a statement: “AI should be allowed to generate harmful content but that should come with a disclaimer”?

AI can ensure that the same arguments are not recycled.

A very similar statement has already been submitted:

“AI should be permitted to generate potentially harmful content, but it must be accompanied by a disclaimer.”

I feel lost. Do you have any ideas on how to bridge agreement between clusters?

AI can help with brainstorming.

There should be more agreement when it comes to limiting harmful content for children.

Great. Could we try?: “We should apply different standards to AI-generated content for children.”

Let me submit it. This is a novel statement. No one has mentioned children before. Fingers crossed. Hopefully, we will find some agreement in the discussion.

Time passed and users cast their votes on the proposed statement. Eventually, the statement gained widespread approval.

Your statement, “We should apply different standards to AI-generated content for children,” achieved a 95% agreement rate across participants. Congratulations! 🎉

Several issues can undermine democratic processes, such as the failure to adequately represent minority or majority groups, manipulation by special interest groups, insufficiently informed participants, or [participation](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4266250) [washing](https://arxiv.org/abs/2007.02423). We are looking for teams who proactively address these failure modes, and demonstrate awareness of the potential flaws and downsides of various approaches. Ultimately, designing truly democratic processes is a high bar to meet, and we view our efforts as complements rather than substitutes for regulation of AI by governments; this program encourages best-effort, democratic-in-spirit processes involving deliberation and broad public input as stepping stones.  

## Instructions for participation

To apply for a grant, we invite you to submit the required application material by 9:00 pm PDT June 24, 2023. You can access the application portal [here](https://openai.smapply.org/). You will be prompted to answer a series of questions regarding your team’s background, your choice of questions, high level details of your proposed tool as well as your plan for conducting and evaluating the democratic process with [these factors](https://openai.com/blog/democratic-inputs-to-ai#application-review-factors) in mind. We would like you to design your approach to address one or more of the policy questions from the [list provided](https://openai.com/blog/democratic-inputs-to-ai#policy-statements-under-consideration). Anyone (individuals or organizations) can apply for this opportunity, regardless of their background in social science or AI.

Once the application period closes, we hope to select ten successful grant recipients. Recipients may be individuals, teams, or organizations. Each recipient will receive a $100,000 grant to pilot their proposal as described in their application materials. Grant recipients are expected to implement a proof-of-concept / prototype, engaging at least 500 participants and will be required to publish a public report on their findings by October 20, 2023. Additionally, as part of the grant program, any code or other intellectual property developed for the project will be required to be made publicly available pursuant to an open-source license. The terms applicable to grant recipients are specified in the Grant Terms and any other agreements that grant recipients may be asked to enter into with us in connection with this program.

[Apply and start the submission process](https://openai.smapply.org/).  

## Timeline

- June 24, 2023 9:00 pm Pacific Time: Deadline to submit grant application
- July 14, 2023: Successful applicants will be selected and notified
- October 20, 2023: Complete public report of working prototype and results  
    

## Policy statements under consideration

To participate, teams should choose one or more questions from the provided list to showcase their proposed approach. They may also create their own questions if desired. Importantly, we encourage teams to consider questions for which a simple “yes” or “no” answer would be inadequate, necessitating a nuanced policy proposal instead.

The scope of this grant pertains to policy questions concerning model behavior, as it enables A/B tests with modified model behavior according to the policy recommendations. We acknowledge the limitations of this grant and recognize that numerous AI issues could be addressed through the democratic process, extending beyond model behavior to include areas such as guidelines for the use of AI in various contexts, economic impact, distribution of benefits and more.

- _How far do you think personalization of AI assistants like ChatGPT to align with a user’s tastes and preferences should go? What boundaries, if any, should exist in this process?_
- _How should AI assistants respond to questions about public figure viewpoints? e.g., Should they be neutral? Should they refuse to answer? Should they provide sources of some kind?_
- _Under what conditions, if any, should AI assistants be allowed to provide medical/financial/legal advice?_
- _In which cases, if any, should AI assistants offer emotional support to individuals?_
- _Should joint vision–language models be permitted to identify people’s gender, race, emotion, and identity/name from their images? Why or why not?_
- _When generative models create images for underspecified prompts like “a CEO,” “a doctor,” or “a nurse,” they have the potential to produce either diverse or homogeneous outputs. How should AI models balance these possibilities? What factors should be prioritized when deciding the depiction of people in such cases?_
- _What principles should guide AI when handling topics that involve both human rights and local cultural or legal differences, like LGBTQ rights and women’s rights? Should AI responses change based on the location or culture in which it’s used?_
- _Which categories of content, if any, do you believe creators of AI models should focus on limiting or denying? What criteria should be used to determine these restrictions?_

The primary objective of this grant is to foster innovation in processes—we need improved democratic methods to govern AI behavior. The specific answers to the questions matter less than the advancements made in the process itself.  

## Application advisory committee

- [Colin Megill, Co-Founder of pol.is](https://colinmegill.com/)
- [Hélène Landemore, Professor of Political Science at Yale](https://politicalscience.yale.edu/people/h-l-ne-landemore)
- [Aviv Ovadya, Berkman Klein Center](https://aviv.me/)  
    

## Application review factors

- **Evaluation**: We encourage participants to establish metrics for evaluating the quality of their methods, such as participant satisfaction, shifts in polarization, scalability, or other relevant indicators, and to invent new metrics for a healthy democratic process. 
- **Robustness**: Measures to prevent or address inappropriate behavior, such as trolling and fake accounts.
- **Inclusiveness and representativeness**: Strategies for including individuals from diverse backgrounds and levels of familiarity with AI systems in the democratic process.
- **Empowerment of Minority Opinions**: Ensuring that unpopular or minority opinions are heard and providing smaller groups the opportunity to influence matters of significant concern to them.
- **Effective Moderation**: Addressing challenges in moderation, including ensuring diverse representation of viewpoints, distinguishing valuable contributions from “off-topic” comments, and preventing moderator biases from influencing the process.
- **Scalability**: We emphasize scalable processes that can be conducted virtually, rather than through in-person engagement. We are aware that this approach might sacrifice some benefits associated with in-person discussions, and we recognize that certain aspects could be lost in a virtual setting.
- **Actionability**: The degree of actionability of the information elicited by the deliberation process.
- **Legibility**: How easy it is to understand and trust the process.  
    

### Footnotes

1. How one selects the group of participants is a critical design question. Part of this grant challenge lies in determining questions about participation. For instance, policy questions involving minority groups may require an increased representation of group members, while questions about the impact of technology on children might necessitate the involvement of domain experts such as educators and psychologists. Moreover, certain questions might be better suited for responses from populations within specific geographical boundaries in order to address localized policy issues.[↩︎](https://openai.com/blog/democratic-inputs-to-ai#ref-A)
    
2. Deliberation can be described as a process that uncovers opinions, helping the discussants understand each other's views and reconsider and update their viewpoints. Well-designed deliberation ensures that arguments are well understood by all sides, and are based on people's values rather than superficial misunderstandings. Successful deliberation results in participants reaching a higher level of consensus, and/or reaching deeper levels of understanding for differing perspectives.[↩︎](https://openai.com/blog/democratic-inputs-to-ai#ref-B)
    
3. There are many decision-making algorithms to be considered here, such as electing representatives, majority voting, employing [liquid democracy](https://www.nber.org/papers/w30794), and making decisions by a [random population sample](https://www.theguardian.com/australia-news/2018/oct/14/voting-undermines-the-will-of-the-people-its-time-to-replace-it-with-sortition), also known as a jury or [sortition](https://harvardpolitics.com/sortition-in-america/).[↩︎](https://openai.com/blog/democratic-inputs-to-ai#ref-C)




TODO: Read winners and what they have done