![[Pasted image 20231024195337.png]]
[2303.11341.pdf (arxiv.org)](https://arxiv.org/pdf/2303.11341.pdf)
[What Does It Take To Catch a Chinchilla? Verifying Rules on Large-Scale Neural Network Training via Compute Monitoring (type3.audio)](https://preview.type3.audio/episode/ai-safety-fundamentals-governance/63a4938b-a1f2-4a52-bacc-685267b2b045)

7.1 Politics of Implementation 

Given the substantial complexity and cost of a monitoring and verification regime for large-scale ML training runs, it will only become a reality if it benefits the key stakeholders required to implement it. In this last section, we discuss the benefits of this proposal among each of the required stakeholders. 

• The global public: Ordinary citizens should worry about the concentration of power associated with private companies possessing large quantities of ML chips, without any meaningful oversight by the public. Training run monitoring is a way to make powerful companies’ advanced ML development accountable to the public, and not just the free market. Most importantly, ordinary people benefit from the security and stability enabled by laws and agreements that limit the most harmful applications of large-scale ML systems. 

• Chipmakers and cloud providers: Absent mechanisms for verifying whether ML chips are used for rule violating training runs, governments may increasingly resort to banning the sale of chips (or even cloud computing access to those chips) to untrusted actors [5]. By enabling provable monitoring of large-scale ML training runs, chipmakers may reverse this trend and may even be able to resume sales to affected markets. 

• AI companies: Responsible AI companies may themselves prefer not to develop a particular capability into their products, but may feel they have no choice due to competitive pressure exerted by less-scrupulous rivals. Verifying training runs would allow responsible AI companies to be recognized for the limits they impose on themselves, and would facilitate industry-wide enforcement of best practices on responsible ML development. 

• Governments and militaries: Governments’ and militaries’ overarching objective is to ensure the security and prosperity of their country. The inability to coordinate with rivals on limits to the development of highly capable ML systems is a threat to their own national security. There would be massive benefit to a system that enabled (even a subset of) countries to verify each others’ adherence with ML training agreements, and thus to maintain an equilibrium of responsible ML development.



![[Pasted image 20231026172837.png]][(185) The Bureaucratic Politics Model - YouTube](https://www.youtube.com/watch?v=1JYy5B9O9oU)

