
**Purpose and research question**
The aim of this paper is to focus on the debate between weak and strong AI, and its relevance in the era of LLMs.

**Disposition**

*Introductions and definitions*
The idea between weak and strong AI originates from Turing's imitation game, and is about whether an AI could imitate a human or not.  These days there are other definitions and versions of it, mostly boiling down to whether AI systems can possibly be at "human-level" in some capacity. 

*Symbol Grounding problem and Chinese room*

One problem is the symbol grounding problem, the problem with regards to how AI systems ground meaning in syntactic symbols. Some papers have argued that the symbol grounding problem is not a problem for LLMs. This relates a lot to the Chinese room argument aswell, regarding the meaning of symbols in what appears to be purely syntactic methods. Do LLMs hold meaning in a way beyond synax? Could the robot response to the Chinese room argument play a role in helping with this?

*Lucas-Penrose arguments*

Another part of the debate is the Lucas-Penrose arguments. Gödel stated what is called Gödel's disjunction, which states that either that the mind exceeds computation or that there are absolutely unsolvable Diophantine questions (or absolutely unprovable statements in general). The idea is that human minds can see the truth of Gödel sentences $F\vdash G\leftrightarrow prov(<G>)$. Gödel argued that this follows from his incompleteness theorems. Lucas then goes on to argue that, from logic alone, one can derive that the mind exceeds computation. However it's pretty much consensus to consider this a very flawed argument. However Penrose revived this argument and has since tried to defend it in a different way. For the weak-strong AI debate, can LLMs "understand" Gödel sentences?

*Practical relevance for the Singularity arguments and self improving LLMs*

As a last question, does this argument matter? Does the probability of humans eventually creating human level intelligence (AGI) superhuman level intelligence (ASI) and the subsequent singularity? Does it matter for the purported existential risk that AI's pose?

Literature

[2402.02243](https://arxiv.org/pdf/2402.02243)
[aclanthology.org/2024.emnlp-main.651.pdf](https://aclanthology.org/2024.emnlp-main.651.pdf)
[The Symbol Grounding Problem](https://arxiv.org/html/cs/9906002)
[tandfonline.com/doi/pdf/10.1080/0020174X.2024.2446241](https://www.tandfonline.com/doi/pdf/10.1080/0020174X.2024.2446241)

[Lucas-Penrose Argument about Gödel’s Theorem | Internet Encyclopedia of Philosophy](https://iep.utm.edu/lp-argue/)
[Gödel's Disjunction: The scope and limits of mathematical knowledge | Oxford Academic](https://academic.oup.com/book/40047)

[Artificial Intelligence (Stanford Encyclopedia of Philosophy)](https://plato.stanford.edu/entries/artificial-intelligence/)
[singularity.pdf](https://consc.net/papers/singularity.pdf)