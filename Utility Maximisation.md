


Utility Maximisation
![[Pasted image 20230714210204.png]]

"Expected utility theorists often interpret probability as measuring individual degree of belief, so that a propositionÂ Eï¿½Â is likely (for an agent) to the extent that that agent is confident ofÂ Eï¿½Â (see, for instance, Ramsey 1926, Savage 1972, Jeffrey 1983). But nothing in the formalism of expected utility theory forces this interpretation on us. We could instead interpret probabilities as objective chances (as in von Neumann and Morgenstern 1944), or as the degrees of belief that are warranted by the evidence, if we thought these were a better guide to rational action."

"  What is it to have a probability on the supposition that the agent choosesÂ Aï¿½? Here, there are two basic types of answer, corresponding to evidential decision theory and causal decision theory."
![[Pasted image 20230715102532.png]]

![[Pasted image 20230715102920.png]]
![[Pasted image 20230715105920.png]]

[Newcomb's Problem - LessWrong](https://www.lesswrong.com/tag/newcomb-s-problem)
Here's a slightly different formulation and discussion on it, using an superintelligencce Omega.

![[Pasted image 20230715120448.png]]

![[Pasted image 20230715120501.png]]



![[Pasted image 20230715120521.png]]
![[Pasted image 20230715120804.png]]

A way to solve the problem of interpersonal utility comparissons:

![[Pasted image 20230715122339.png]]


This section from here is also good [Normative Theories of Rational Choice: Rivals to Expected Utility (Stanford Encyclopedia of Philosophy)](https://plato.stanford.edu/entries/rationality-normative-nonutility/) Especially since it considers the different formalisms between objective vs subjective interpretations of probability theory. 
![[Pasted image 20230717091620.png]]


## Inconsumensrability

![[Pasted image 20230717103816.png]]


![[Pasted image 20230717121211.png]]
They stole my idea about partial orders on preferences!
Yeah from before you were even born LOL!
# ðŸ˜¡
![[Pasted image 20230717122859.png]]


This was found over here [Incommensurable Values (Stanford Encyclopedia of Philosophy)](https://plato.stanford.edu/entries/value-incommensurable/#DeliChoi): People generally prefer noncommodities over commodities
![[Pasted image 20230717121348.png]]
TODO: Read their scientific study




## Arguments for expected utility maximisation

![[Pasted image 20230715123920.png]]
This is followed by a definition of the weak and strong law of large numbers.

![[Pasted image 20230715124557.png]]
Idea: The long run argument could still hold for instances where this is the case i.e lotteries where (almost always) the expected utility is <0 which implies one isn't rational when playing the lottery. 
![[Pasted image 20230715125741.png]]

![[Pasted image 20230715130037.png]]
Wait, is that Cournot the engine guy?! 
# ðŸ˜³


### The representation theorems:

![[Pasted image 20230715140521.png]]


![[Pasted image 20230717093159.png]]
Converting Celsius to Fahrenheit is a pedagogical example of an affine transformation. 

Idea: Being unique up to affine transformation means that there is one and only one utility function that represents a preference relation which might still represent that preference relation under affine transformation.

![[Pasted image 20230717093604.png]]
With analogues for subjective interpretation of probability theory. 


## Infinite utility

Pascal's Wager
![[Pasted image 20230717094308.png]]

St. Peters Paradox
![[Pasted image 20230717095345.png]]

![[Pasted image 20230717095701.png]]



## Arguments against maximising expected utility

![[Pasted image 20230715215700.png]]


## Imprecise and Ambiguous probabilities


![[Pasted image 20230718105944.png]]
My own expected utility calculation:
$f_1 = 100\frac{1}{3}\approx 33$. 
$f_2 = 100p_b$
where $p_b\in [0, \frac{2}{3}]$
Under equal probability distribution, it is less than a third with 50% probability and greater than a third with 50% probability. So expected utility is still roughly 33 (!) 

![[Pasted image 20230718110001.png]]
TODO: Figure out why this violates the sure-thing principle. 


![[Pasted image 20230718133832.png]]
![[Pasted image 20230718135830.png]]

TODO: Read 4.3 and 4.4 they are quite complicated. 
[Normative Theories of Rational Choice: Rivals to Expected Utility (Stanford Encyclopedia of Philosophy)](https://plato.stanford.edu/entries/rationality-normative-nonutility/#PropDeciRule_1)


## Applications

![[Pasted image 20230717131355.png]]



## Risk Aversion and Risk Seeking
[Normative Theories of Rational Choice: Rivals to Expected Utility (Stanford Encyclopedia of Philosophy)](https://plato.stanford.edu/entries/rationality-normative-nonutility/#RiskAver)

Idea: If there is a temporal gap between choosing a lottery and winning the lottery, could an AGI be risk-seeking and then rapidly improve its odds at winning, or atleast, diminishing the worst risks? This way, a safe bet with less expected utility would not be preferred by the AGI. 

