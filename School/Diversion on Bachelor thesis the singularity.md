

# The singularity argument (Chalmers)

A --> A+ -->A++ ....

The Singularity, barring defeaters, will eventually come to pass

The three premises

Possibility of AGI
AGI leads to AGI+ and so on indefinitely
We get superhuman AI (ASI)

We could eventually conceive of using brute simulations of human minds to do it.

Defeaters like nuclear war might prevent it. 

## Potential counter arguments:

From the book why machines will never rule the world: 
Premise 1 and 2 are false. Dynamical systems theory show that chaotic behavior are to difficult to model, making it impossible to model intelligence in the way needed. AGI would thus be impossible.

Lucas-Penrose argument might imply 1 is false (although Lucas disagrees)

Chinese room argument might imply 1 is false (although Searle disagrees?)


Singularity violates theorems in formal logic
Chalmers response



## Pro-Singularity arguments


Boströms simulation argument implies that the singularity has already happened. 


Tipler saysj the laws of physics implies the invetibatility of the singularity?

Gödel machines will lead to a singularity (umm LOL what happened to that?). NARS people claim theirs will be AGI. LLM people claim they will scale to AGI. Seems like only the LLM people have a shot tbh. 



## Consequences


X-risk Boström
Hutter's AI society



$\neg(\exists x N(x) \rightarrow \exists! x N(x))$


