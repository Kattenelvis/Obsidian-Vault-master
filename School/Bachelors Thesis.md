
**Purpose and research question**
The aim of this paper is to focus on the debate between weak and strong AI, and its relevance in the era of LLMs.

**Disposition**

*Introductions and definitions*
The idea between weak and strong AI originates from Turing's imitation game, and is about whether an AI could imitate a human or not.  These days there are other definitions and versions of it, mostly boiling down to whether AI systems can possibly be at "human-level" in some capacity. 

*Symbol Grounding problem and Chinese room*

One problem is the symbol grounding problem, the problem with regards to how AI systems ground meaning in syntactic symbols. Some papers have argued that the symbol grounding problem is not a problem for LLMs. This relates a lot to the Chinese room argument aswell, regarding the meaning of symbols in what appears to be purely syntactic methods. Do LLMs hold meaning in a way beyond synax? Could the robot response to the Chinese room argument play a role in helping with this?

*Lucas-Penrose arguments*

Another part of the debate is the Lucas-Penrose arguments. Gödel stated what is called Gödel's disjunction, which states that either that the mind exceeds computation or that there are absolutely unsolvable Diophantine questions (or absolutely unprovable statements in general). The idea is that human minds can see the truth of Gödel sentences $F\vdash G\leftrightarrow prov(<G>)$. Gödel argued that this follows from his incompleteness theorems. Lucas then goes on to argue that, from logic alone, one can derive that the mind exceeds computation. However it's pretty much consensus to consider this a very flawed argument. However Penrose revived this argument and has since tried to defend it in a different way. For the weak-strong AI debate, can LLMs "understand" Gödel sentences?

*Practical relevance for the Singularity arguments and self improving LLMs*

As a last question, does this argument matter? Does the probability of humans eventually creating human level intelligence (AGI) superhuman level intelligence (ASI) and the subsequent singularity? Does it matter for the purported existential risk that AI's pose?

Literature

[2402.02243](https://arxiv.org/pdf/2402.02243)
[aclanthology.org/2024.emnlp-main.651.pdf](https://aclanthology.org/2024.emnlp-main.651.pdf)
[The Symbol Grounding Problem](https://arxiv.org/html/cs/9906002)
[tandfonline.com/doi/pdf/10.1080/0020174X.2024.2446241](https://www.tandfonline.com/doi/pdf/10.1080/0020174X.2024.2446241)

[Lucas-Penrose Argument about Gödel’s Theorem | Internet Encyclopedia of Philosophy](https://iep.utm.edu/lp-argue/)
[Gödel's Disjunction: The scope and limits of mathematical knowledge | Oxford Academic](https://academic.oup.com/book/40047)

[Artificial Intelligence (Stanford Encyclopedia of Philosophy)](https://plato.stanford.edu/entries/artificial-intelligence/)
[singularity.pdf](https://consc.net/papers/singularity.pdf)





Ideas: Dcennett, Heuristics, AI and philosophy

Looking into LLMs which now have an increased level of mathematical competense, perhaps asking chatGPT on deriving gödel sentences. Are humans really different?


Historical overview of the arguments?

Gödel's disjunction
Lucas's Argument
Benaceraff's response  (i.e our own Gödel sentences describing humans is too complicated for us to know)
Lucas's counter-response
Putnam's response
Dennetts response (we don't walk around as first-order arithmetic staters) and Lucas 1990 response
Boyer 1983 on finite mind and lucas 1990 response
Penroses revival and connection with orchestrated collapse theory
Chalmers response
Penrose's counter arguments
Large Language Models and mathematical reasoning
New empirical confirmation of Penrose or just a farce?


Shapiro? Putnam? Williamson?



Gödel's incompleteness theorems

For $\omega$-consitent enumeratively axiomatizable formal systems with sufficient arithmetic, there exists statements which are true but unprovable. The proof involves utilizing diagonalization to create a partially self-referential statement of the type

$F\vdash A\leftrightarrow F(\lceil A\rceil)$

For which we simply substitute $A$ for the "not provable" predicate, giving us a Gödel sentence G

$F\vdash G\leftrightarrow \neg Prov(\lceil G\rceil)$







