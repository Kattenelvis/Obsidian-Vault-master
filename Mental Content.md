
Instuderingsfrågor:

1. "We could ask the same question about the intentionality of words and natural language sentences: how do they get their meaning? An obvious answer is: from the thoughts of the language users."
   The meaning of natural language sentences is the content of thoughts of the users of that language. However mental representations don't have the content be thoughts since mental representations are thoughts so there would be an infinite regress. Therefore some representations have underived intentionality. 
   
2. To have a suitable shorthand, I will use the term ‘subpersonal’ to cover representations for which content-determination does not depend on those complicating features: consciousness, justification for the person, a role in reason-giving interactions with other people, or being structured like natural language sentences.

3. My overall philosophical strategy, then, is to start with the subpersonal and work upwards. This inverts the normal approach.2 But the normal approach has not been entirely successful to date.
   
4. Content bearing physical particulars which interact with eachother in an alogithmic way to produce an output that's either another representation or behaviour


8. Every component (vehicle) in an implemented algorithm must have two properties: external/distal relation


Correlation information P(Fa | Gb) =/= P(Gb) which is based on some objective chanse. That is, correlation information is only explanatoraly adequate for content if there is objective chanse if there is some objective chanse. The epistemic problem is that there are only subjective chanses given finite experience, the researcher needs some kind of omniscience for the explanation to work. Requires "omniscience" about region D. 